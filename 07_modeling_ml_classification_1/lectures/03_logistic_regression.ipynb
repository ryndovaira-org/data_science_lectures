{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Логистическая регрессия (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Источники:**\n",
    "\n",
    "\n",
    "[Логистическая регрессия](https://ru.wikipedia.org/wiki/%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F)\n",
    "\n",
    "[Логистическая регрессия (Logistic Regression)](https://wiki.loginom.ru/articles/logistic-regression.html)\n",
    "\n",
    "[Multinomial Logistic Regression With Python](https://machinelearningmastery.com/multinomial-logistic-regression-with-python/)\n",
    "\n",
    "[Logistic regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)\n",
    "\n",
    "[Multinomial logistic regression](https://en.wikipedia.org/wiki/Multinomial_logistic_regression#:~:text=In%20statistics%2C%20multinomial%20logistic%20regression,than%20two%20possible%20discrete%20outcomes.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ВНИМАНИЕ: необходимо удостовериться, что виртуальная среда выбрана правильно!\n",
    "\n",
    "# Для MacOS/Ubuntu\n",
    "# !which pip\n",
    "\n",
    "# Для Windows\n",
    "# !where pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !conda install matplotlib numpy scikit-learn seaborn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "\n",
    "[Источник (CustomerChurnRate)](https://www.kaggle.com/gangliu/customerchurnrate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>longmon</th>\n",
       "      <th>tollmon</th>\n",
       "      <th>equipmon</th>\n",
       "      <th>cardmon</th>\n",
       "      <th>wiremon</th>\n",
       "      <th>longten</th>\n",
       "      <th>tollten</th>\n",
       "      <th>cardten</th>\n",
       "      <th>voice</th>\n",
       "      <th>pager</th>\n",
       "      <th>internet</th>\n",
       "      <th>callwait</th>\n",
       "      <th>confer</th>\n",
       "      <th>ebill</th>\n",
       "      <th>loglong</th>\n",
       "      <th>logtoll</th>\n",
       "      <th>lninc</th>\n",
       "      <th>custcat</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>136.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>20.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.25</td>\n",
       "      <td>35.70</td>\n",
       "      <td>42.00</td>\n",
       "      <td>211.45</td>\n",
       "      <td>125.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>3.03</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>288.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>157.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.84</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.05</td>\n",
       "      <td>45.00</td>\n",
       "      <td>50.10</td>\n",
       "      <td>23.25</td>\n",
       "      <td>64.90</td>\n",
       "      <td>239.55</td>\n",
       "      <td>1873.05</td>\n",
       "      <td>880.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.10</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.45</td>\n",
       "      <td>166.10</td>\n",
       "      <td>145.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.96</td>\n",
       "      <td>3.09</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>55.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.35</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>973.10</td>\n",
       "      <td>1343.50</td>\n",
       "      <td>720.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.42</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>34.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>203.25</td>\n",
       "      <td>959.40</td>\n",
       "      <td>435.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.79</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.18</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>6.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.85</td>\n",
       "      <td>23.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.90</td>\n",
       "      <td>128.45</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>24.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.70</td>\n",
       "      <td>47.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.75</td>\n",
       "      <td>64.00</td>\n",
       "      <td>186.60</td>\n",
       "      <td>1152.90</td>\n",
       "      <td>780.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.16</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>61.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>190.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.55</td>\n",
       "      <td>26.50</td>\n",
       "      <td>44.10</td>\n",
       "      <td>1063.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1600.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.82</td>\n",
       "      <td>3.24</td>\n",
       "      <td>5.25</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0     11.00 33.00     7.00  136.00 5.00    5.00   0.00      1.00      1.00   \n",
       "1     33.00 33.00    12.00   33.00 2.00    0.00   0.00      0.00      0.00   \n",
       "2     23.00 30.00     9.00   30.00 1.00    2.00   0.00      0.00      0.00   \n",
       "3     38.00 35.00     5.00   76.00 2.00   10.00   1.00      1.00      1.00   \n",
       "4      7.00 35.00    14.00   80.00 2.00   15.00   0.00      1.00      0.00   \n",
       "..      ...   ...      ...     ...  ...     ...    ...       ...       ...   \n",
       "195   55.00 44.00    24.00   83.00 1.00   23.00   0.00      1.00      0.00   \n",
       "196   34.00 23.00     3.00   24.00 1.00    7.00   0.00      1.00      0.00   \n",
       "197    6.00 32.00    10.00   47.00 1.00   10.00   0.00      1.00      0.00   \n",
       "198   24.00 30.00     0.00   25.00 4.00    5.00   0.00      1.00      1.00   \n",
       "199   61.00 50.00    16.00  190.00 2.00   22.00   1.00      1.00      1.00   \n",
       "\n",
       "     longmon  tollmon  equipmon  cardmon  wiremon  longten  tollten  cardten  \\\n",
       "0       4.40    20.75      0.00    15.25    35.70    42.00   211.45   125.00   \n",
       "1       9.45     0.00      0.00     0.00     0.00   288.80     0.00     0.00   \n",
       "2       6.30     0.00      0.00     0.00     0.00   157.05     0.00     0.00   \n",
       "3       6.05    45.00     50.10    23.25    64.90   239.55  1873.05   880.00   \n",
       "4       7.10    22.00      0.00    23.75     0.00    47.45   166.10   145.00   \n",
       "..       ...      ...       ...      ...      ...      ...      ...      ...   \n",
       "195    17.35    24.50      0.00    14.25     0.00   973.10  1343.50   720.00   \n",
       "196     6.00    28.00      0.00    12.75     0.00   203.25   959.40   435.00   \n",
       "197     3.85    23.75      0.00    12.50     0.00    29.90   128.45    80.00   \n",
       "198     8.70    47.75      0.00    32.75    64.00   186.60  1152.90   780.00   \n",
       "199    16.85     0.00     42.55    26.50    44.10  1063.15     0.00  1600.00   \n",
       "\n",
       "     voice  pager  internet  callwait  confer  ebill  loglong  logtoll  lninc  \\\n",
       "0     1.00   1.00      0.00      1.00    1.00   0.00     1.48     3.03   4.91   \n",
       "1     0.00   0.00      0.00      0.00    0.00   0.00     2.25     3.24   3.50   \n",
       "2     0.00   0.00      0.00      0.00    1.00   0.00     1.84     3.24   3.40   \n",
       "3     1.00   1.00      1.00      1.00    1.00   1.00     1.80     3.81   4.33   \n",
       "4     1.00   0.00      0.00      1.00    1.00   0.00     1.96     3.09   4.38   \n",
       "..     ...    ...       ...       ...     ...    ...      ...      ...    ...   \n",
       "195   0.00   0.00      0.00      0.00    1.00   0.00     2.85     3.20   4.42   \n",
       "196   0.00   0.00      0.00      1.00    1.00   0.00     1.79     3.33   3.18   \n",
       "197   0.00   0.00      0.00      1.00    1.00   0.00     1.35     3.17   3.85   \n",
       "198   1.00   1.00      1.00      1.00    1.00   1.00     2.16     3.87   3.22   \n",
       "199   0.00   0.00      1.00      0.00    0.00   1.00     2.82     3.24   5.25   \n",
       "\n",
       "     custcat  churn  \n",
       "0       4.00   1.00  \n",
       "1       1.00   1.00  \n",
       "2       3.00   0.00  \n",
       "3       4.00   0.00  \n",
       "4       3.00   0.00  \n",
       "..       ...    ...  \n",
       "195     3.00   0.00  \n",
       "196     3.00   0.00  \n",
       "197     3.00   0.00  \n",
       "198     4.00   1.00  \n",
       "199     2.00   0.00  \n",
       "\n",
       "[200 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./../../data/ChurnData.csv')\n",
    "\n",
    "# показать все колонки\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# изменить формат отображения с помощью средства форматирования\n",
    "# (float без E, а 2 знаков после запятой)\n",
    "# (для удобства чтения)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# отобразить первые 5 и последние 5 строк\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tenure    200 non-null    float64\n",
      " 1   age       200 non-null    float64\n",
      " 2   address   200 non-null    float64\n",
      " 3   income    200 non-null    float64\n",
      " 4   ed        200 non-null    float64\n",
      " 5   employ    200 non-null    float64\n",
      " 6   equip     200 non-null    float64\n",
      " 7   callcard  200 non-null    float64\n",
      " 8   wireless  200 non-null    float64\n",
      " 9   churn     200 non-null    float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 15.8 KB\n"
     ]
    }
   ],
   "source": [
    "df = df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',  'callcard', 'wireless','churn']]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вероятность (Probability)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Различия между Линейной (Linear) и Логистической (Logistic) регрессией (Regression)\n",
    "\n",
    "\n",
    "<img src=\"images/linear_vs_logistic_regression_2.png\" width=\"600\">\n",
    "\n",
    "\n",
    "В то время как **линейная регрессия** подходит для оценки **непрерывных значений** (например, оценок цены дома), это не лучший инструмент для прогнозирования класса, то есть **дискретных значений**.\n",
    "\n",
    "Чтобы **оценить класс**, нужно какое-то руководство в том, какой класс будет наиболее вероятным для этого набора признаков. Для этого можно использовать **логистическую регрессию**.\n",
    "\n",
    "**Логистическая регрессия** - это **разновидность линейной регрессии**, полезная, когда наблюдаемая зависимая переменная $y$ является категориальной. \n",
    "\n",
    "**Логистическая регрессия** соответствует специальной s-образной кривой, взяв линейную регрессию и преобразовав числовую оценку в вероятность с помощью следующей функции, которая называется сигмоидной функцией $\\sigma$:\n",
    "\n",
    "$$\n",
    "ℎ_\\theta(𝑥) = \\sigma({\\theta^TX}) =  \\frac {e^{(\\theta_0 + \\theta_1  x_1 + \\theta_2  x_2 +...)}}{1 + e^{(\\theta_0 + \\theta_1  x_1 + \\theta_2  x_2 +\\cdots)}}\n",
    "$$\n",
    "Или:\n",
    "$$\n",
    "Probability\\space of \\space Class_1 =  P(y=1|X) = \\sigma({\\theta^TX}) = \\frac{e^{\\theta^TX}}{1+e^{\\theta^TX}} \n",
    "$$\n",
    "\n",
    "В этом уравнении ${\\theta^TX}$ - это результат регрессии (сумма переменных, взвешенных коэффициентами), `exp` - экспоненциальная функция, а $\\sigma(\\theta^TX)$ - сигмоида или [логистическая функция](https://ru.wikipedia.org/wiki/%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D1%83%D1%80%D0%B0%D0%B2%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5), также называется логистической кривой. Это обычная S-образная форма (сигмовидная кривая).\n",
    "\n",
    "<img src=\"images/linear_vs_logistic_regression_1.png\" width=\"600\">\n",
    "\n",
    "\n",
    "Итак, вкратце, логистическая регрессия передает входные данные через логистическую / сигмоиду, но затем обрабатывает результат как вероятность:\n",
    "\n",
    "<img src=\"images/log_regr_prob.png\" width=\"400\">\n",
    "\n",
    "**Логистическая регрессия выдаёт ответ в виде вероятности бинарного события (1 или 0).**\n",
    "\n",
    "Эта модель применяется для решения задач классификации — объект $x$ можно отнести к классу $y=1$, если предсказанная моделью вероятность $P\\{y=1|x\\}>0.5$, и к классу $y=0$ в противном случае.\n",
    "А логистическая регрессия **лучшим образом подходит, когда выходная переменная принимает только два значения**.\n",
    "\n",
    "Цель алгоритма **логистической регрессии** - найти наилучшие параметры $\\theta$ для $ℎ_\\theta(𝑥)$ = $\\sigma({\\theta^TX})$ таким образом, чтобы наилучшим образом предсказать класс каждого случая.\n",
    "\n",
    "**Для улучшения обобщающей способности получающейся модели, то есть уменьшения эффекта переобучения, на практике часто рассматривается логистическая регрессия с регуляризацией.**\n",
    "\n",
    "<img src=\"images/2d_log_reg.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бинарная классификация (ровно 2 класса)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предварительная обработка (pre-processing) и выбор (selection) данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
    "y = np.asarray(df['churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.6961288 ,\n",
       "        -0.58477841, -0.85972695],\n",
       "       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -0.6433592 ,\n",
       "        -1.14437497, -0.85972695],\n",
       "       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -1.42318853,\n",
       "        -0.92053635, -0.85972695],\n",
       "       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.6433592 ,\n",
       "        -0.02518185,  1.16316   ],\n",
       "       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.6433592 ,\n",
       "         0.53441472, -0.85972695]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# нормализация\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, solver='liblinear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5862587 , 0.4137413 ],\n",
       "       [0.49465581, 0.50534419],\n",
       "       [0.45932668, 0.54067332],\n",
       "       [0.51345216, 0.48654784],\n",
       "       [0.5417615 , 0.4582385 ],\n",
       "       [0.49240469, 0.50759531],\n",
       "       [0.47032563, 0.52967437],\n",
       "       [0.51872717, 0.48127283],\n",
       "       [0.39225893, 0.60774107],\n",
       "       [0.45682503, 0.54317497],\n",
       "       [0.57076645, 0.42923355],\n",
       "       [0.75767701, 0.24232299],\n",
       "       [0.53907823, 0.46092177],\n",
       "       [0.65176321, 0.34823679],\n",
       "       [0.5709428 , 0.4290572 ],\n",
       "       [0.72820573, 0.27179427],\n",
       "       [0.56138775, 0.43861225],\n",
       "       [0.53086271, 0.46913729],\n",
       "       [0.45224233, 0.54775767],\n",
       "       [0.71479525, 0.28520475],\n",
       "       [0.47845779, 0.52154221],\n",
       "       [0.42598256, 0.57401744],\n",
       "       [0.4465493 , 0.5534507 ],\n",
       "       [0.46245438, 0.53754562],\n",
       "       [0.57551773, 0.42448227],\n",
       "       [0.43717559, 0.56282441],\n",
       "       [0.48227469, 0.51772531],\n",
       "       [0.46961714, 0.53038286],\n",
       "       [0.4969288 , 0.5030712 ],\n",
       "       [0.58020843, 0.41979157],\n",
       "       [0.49271665, 0.50728335],\n",
       "       [0.55879628, 0.44120372],\n",
       "       [0.56145542, 0.43854458],\n",
       "       [0.52069619, 0.47930381],\n",
       "       [0.55224911, 0.44775089],\n",
       "       [0.4151028 , 0.5848972 ],\n",
       "       [0.64798279, 0.35201721],\n",
       "       [0.67038063, 0.32961937],\n",
       "       [0.37522213, 0.62477787],\n",
       "       [0.69094443, 0.30905557]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получить вероятности\n",
    "y_predicted_prob = model.predict_proba(X_test)\n",
    "y_predicted_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка качества модели (Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Матрица ошибок (confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7ff3abf821c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(model, X_test, y_test, cmap='plasma')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.72      0.77        25\n",
      "         1.0       0.61      0.73      0.67        15\n",
      "\n",
      "    accuracy                           0.73        40\n",
      "   macro avg       0.71      0.73      0.72        40\n",
      "weighted avg       0.74      0.72      0.73        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6052882939554263"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, y_predicted_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мультиклассовая классификация (> 2 классов) / Multinomial logistic regression\n",
    "\n",
    "Полиномиальная логистическая регрессия — это расширение логистической регрессии для мультиклассовой классификации.\n",
    "\n",
    "По умолчанию логистическая регрессия не может использоваться для задач классификации, которые имеют более двух меток классов (мультиклассовая классификация).\n",
    "\n",
    "\n",
    "В `sklearn` реализации в случае нескольких классов алгоритм обучения использует схему **one-vs-rest (OvR)**, если опция `multi_class `установлена на `ovr`, и использует потерю кросс-энтропии (cross-entropy loss), если опция `multi_class` установлена на `multinomial`. По умолчанию установлен вариант `auto`, в таком случае выбирается `ovr`, если данные являются двоичными, или если solver = `liblinear`, и в противном случае выбирает `multinomial`.\n",
    "\n",
    "Если выбран вариант `ovr`, то для каждой метки подходит двоичная задача. Для `multinomial` функция потерь (loss) полином, соответствующие всему распределению вероятностей, даже если данные являются двоичными. Значение `multinomial` недоступно, если solver = `liblinear`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предварительная обработка (pre-processing) и выбор (selection) данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.00    59\n",
       "2.00    48\n",
       "1.00    40\n",
       "3.00    36\n",
       "5.00    17\n",
       "Name: ed, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(df[['tenure', 'age', 'address', 'income', 'churn', 'employ', 'equip']])\n",
    "y = np.asarray(df['ed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.56469673,\n",
       "        -0.58477841, -0.85972695],\n",
       "       [-0.11604313, -0.62595491,  0.03454064, -0.32886061,  1.56469673,\n",
       "        -1.14437497, -0.85972695],\n",
       "       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -0.63910148,\n",
       "        -0.92053635, -0.85972695],\n",
       "       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.63910148,\n",
       "        -0.02518185,  1.16316   ],\n",
       "       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.63910148,\n",
       "         0.53441472, -0.85972695]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# нормализация\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, solver='liblinear')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 2., 4., 2., 1., 4., 1., 4., 1., 2., 2., 2., 1., 1., 4., 5., 4.,\n",
       "       1., 1., 1., 1., 4., 4., 2., 1., 1., 4., 4., 4., 2., 1., 2., 2., 1.,\n",
       "       2., 2., 4., 2., 4., 2.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17104502, 0.19977776, 0.20468063, 0.23378236, 0.19071423],\n",
       "       [0.19204248, 0.23067691, 0.20830136, 0.2017868 , 0.16719244],\n",
       "       [0.16053193, 0.20221629, 0.20687576, 0.23791105, 0.19246496],\n",
       "       [0.19355016, 0.22488806, 0.20741145, 0.20186283, 0.17228751],\n",
       "       [0.22918934, 0.20419075, 0.19609921, 0.18746013, 0.18306057],\n",
       "       [0.15908416, 0.18564451, 0.19743639, 0.26203139, 0.19580354],\n",
       "       [0.23977767, 0.21260255, 0.191711  , 0.17275442, 0.18315436],\n",
       "       [0.19442411, 0.20561062, 0.1971444 , 0.22461161, 0.17820926],\n",
       "       [0.22874619, 0.21386259, 0.19640018, 0.18227129, 0.17871976],\n",
       "       [0.20229587, 0.22243194, 0.20430535, 0.1958465 , 0.17512034],\n",
       "       [0.20199977, 0.22856792, 0.2045404 , 0.19535873, 0.16953318],\n",
       "       [0.20975135, 0.22100736, 0.20266031, 0.1935953 , 0.17298568],\n",
       "       [0.24442816, 0.20958768, 0.19332201, 0.17280567, 0.17985648],\n",
       "       [0.23374183, 0.20912263, 0.19436885, 0.17857806, 0.18418863],\n",
       "       [0.17107798, 0.17966316, 0.19389158, 0.25572231, 0.19964496],\n",
       "       [0.20369793, 0.17924759, 0.17256395, 0.18069164, 0.26379888],\n",
       "       [0.1902141 , 0.19123098, 0.19836928, 0.2210437 , 0.19914194],\n",
       "       [0.24547728, 0.20422335, 0.19130109, 0.1749495 , 0.18404877],\n",
       "       [0.24187677, 0.20760327, 0.19192573, 0.17463388, 0.18396034],\n",
       "       [0.24023338, 0.20016125, 0.19097067, 0.18092161, 0.18771309],\n",
       "       [0.24540595, 0.20338795, 0.19298212, 0.17767691, 0.18054707],\n",
       "       [0.19251265, 0.20855539, 0.19805742, 0.22487154, 0.17600299],\n",
       "       [0.18580077, 0.19273147, 0.20095336, 0.22832762, 0.19218678],\n",
       "       [0.18730069, 0.23287565, 0.20931915, 0.20238848, 0.16811603],\n",
       "       [0.22192597, 0.20724712, 0.19823903, 0.19064063, 0.18194725],\n",
       "       [0.24430584, 0.20281591, 0.19071536, 0.17397767, 0.18818523],\n",
       "       [0.19245931, 0.18676646, 0.19821435, 0.22218631, 0.20037358],\n",
       "       [0.16554688, 0.20044856, 0.20707591, 0.23756518, 0.18936348],\n",
       "       [0.18705853, 0.18823084, 0.19948899, 0.22623248, 0.19898916],\n",
       "       [0.19115468, 0.22909049, 0.20791105, 0.2032145 , 0.16862929],\n",
       "       [0.2191407 , 0.21403247, 0.19750235, 0.18831489, 0.18100959],\n",
       "       [0.21281325, 0.219661  , 0.20042544, 0.18808278, 0.17901754],\n",
       "       [0.20425358, 0.22868589, 0.20420701, 0.1921347 , 0.17071881],\n",
       "       [0.21872022, 0.21853952, 0.19920319, 0.18378196, 0.17975511],\n",
       "       [0.19660211, 0.22873831, 0.20611993, 0.1994323 , 0.16910734],\n",
       "       [0.19626423, 0.2253979 , 0.20343795, 0.19339101, 0.18150891],\n",
       "       [0.17038572, 0.17770882, 0.19399515, 0.25686951, 0.2010408 ],\n",
       "       [0.20742836, 0.22230267, 0.20270033, 0.19407221, 0.17349642],\n",
       "       [0.2000787 , 0.1839133 , 0.19369671, 0.21502295, 0.20728834],\n",
       "       [0.18227735, 0.23554268, 0.21050984, 0.20647935, 0.16519077]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получить вероятности\n",
    "y_predicted_prob = model.predict_proba(X_test)\n",
    "y_predicted_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка качества модели (Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Матрица ошибок (confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7ff3afe3cf40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(model, X_test, y_test, cmap='plasma')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.54      0.54      0.54        13\n",
      "         2.0       0.23      0.27      0.25        11\n",
      "         3.0       0.00      0.00      0.00         5\n",
      "         4.0       0.38      0.50      0.43        10\n",
      "         5.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38        40\n",
      "   macro avg       0.23      0.26      0.24        40\n",
      "weighted avg       0.33      0.38      0.35        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ira/anaconda3/envs/LevelUp_DataScience/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ira/anaconda3/envs/LevelUp_DataScience/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ira/anaconda3/envs/LevelUp_DataScience/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.564175207450456"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, y_predicted_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LevelUp_DataScience] *",
   "language": "python",
   "name": "conda-env-LevelUp_DataScience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}