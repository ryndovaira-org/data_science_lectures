{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –õ–∏–Ω–µ–π–Ω–æ–π (Linear) –∏ –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π (Logistic) —Ä–µ–≥—Ä–µ—Å—Å–∏–µ–π (Regression)\n",
    "\n",
    "\n",
    "<img src=\"images/linear_vs_logistic_regression_2.png\" width=\"600\">\n",
    "\n",
    "\n",
    "–í —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ **–ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è** –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ **–Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π** (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—Ü–µ–Ω–æ–∫ —Ü–µ–Ω—ã –¥–æ–º–∞), —ç—Ç–æ –Ω–µ –ª—É—á—à–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞, —Ç–æ –µ—Å—Ç—å **–¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π**.\n",
    "\n",
    "–ß—Ç–æ–±—ã **–æ—Ü–µ–Ω–∏—Ç—å –∫–ª–∞—Å—Å**, –Ω—É–∂–Ω–æ –∫–∞–∫–æ–µ-—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –≤ —Ç–æ–º, –∫–∞–∫–æ–π –∫–ª–∞—Å—Å –±—É–¥–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–º –¥–ª—è —ç—Ç–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –î–ª—è —ç—Ç–æ–≥–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é**.\n",
    "\n",
    "**–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è** - —ç—Ç–æ **—Ä–∞–∑–Ω–æ–≤–∏–¥–Ω–æ—Å—Ç—å –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏**, –ø–æ–ª–µ–∑–Ω–∞—è, –∫–æ–≥–¥–∞ –Ω–∞–±–ª—é–¥–∞–µ–º–∞—è –∑–∞–≤–∏—Å–∏–º–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è $y$ —è–≤–ª—è–µ—Ç—Å—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–π. \n",
    "\n",
    "**–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è** —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π s-–æ–±—Ä–∞–∑–Ω–æ–π –∫—Ä–∏–≤–æ–π, –≤–∑—è–≤ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–≤ —á–∏—Å–ª–æ–≤—É—é –æ—Ü–µ–Ω–∫—É –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å –ø–æ–º–æ—â—å—é —Å–ª–µ–¥—É—é—â–µ–π —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è —Å–∏–≥–º–æ–∏–¥–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π $\\sigma$:\n",
    "\n",
    "$$\n",
    "‚Ñé_\\theta(ùë•) = \\sigma({\\theta^TX}) =  \\frac {e^{(\\theta_0 + \\theta_1  x_1 + \\theta_2  x_2 +...)}}{1 + e^{(\\theta_0 + \\theta_1  x_1 + \\theta_2  x_2 +\\cdots)}}\n",
    "$$\n",
    "–ò–ª–∏:\n",
    "$$\n",
    "Probability\\space of \\space Class_1 =  P(y=1|X) = \\sigma({\\theta^TX}) = \\frac{e^{\\theta^TX}}{1+e^{\\theta^TX}} \n",
    "$$\n",
    "\n",
    "–í —ç—Ç–æ–º —É—Ä–∞–≤–Ω–µ–Ω–∏–∏ ${\\theta^TX}$ - —ç—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (—Å—É–º–º–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö, –≤–∑–≤–µ—à–µ–Ω–Ω—ã—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏), `exp` - —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –∞ $\\sigma(\\theta^TX)$ - —Å–∏–≥–º–æ–∏–¥–∞ –∏–ª–∏ [–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è](https://ru.wikipedia.org/wiki/%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D1%83%D1%80%D0%B0%D0%B2%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5), —Ç–∞–∫–∂–µ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∫—Ä–∏–≤–æ–π. –≠—Ç–æ –æ–±—ã—á–Ω–∞—è S-–æ–±—Ä–∞–∑–Ω–∞—è —Ñ–æ—Ä–º–∞ (—Å–∏–≥–º–æ–≤–∏–¥–Ω–∞—è –∫—Ä–∏–≤–∞—è).\n",
    "\n",
    "<img src=\"images/linear_vs_logistic_regression_1.png\" width=\"600\">\n",
    "\n",
    "\n",
    "–ò—Ç–∞–∫, –≤–∫—Ä–∞—Ç—Ü–µ, –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –ø–µ—Ä–µ–¥–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é / —Å–∏–≥–º–æ–∏–¥—É, –Ω–æ –∑–∞—Ç–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å:\n",
    "\n",
    "<img src=\"images/log_regr_prob.png\" width=\"400\">\n",
    "\n",
    "–¶–µ–ª—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞ **–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏** - –Ω–∞–π—Ç–∏ –Ω–∞–∏–ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã $\\theta$ –¥–ª—è $‚Ñé_\\theta(ùë•)$ = $\\sigma({\\theta^TX})$ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –Ω–∞–∏–ª—É—á—à–∏–º –æ–±—Ä–∞–∑–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∫–ª–∞—Å—Å –∫–∞–∂–¥–æ–≥–æ —Å–ª—É—á–∞—è.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ò–º–ø–æ—Ä—Ç –ø–∞–∫–µ—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "`ChurnData.csv` (–û—Ç—Ç–æ–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤):\n",
    "\n",
    "[Dataset source](https://www.kaggle.com/gangliu/customerchurnrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>longmon</th>\n",
       "      <th>...</th>\n",
       "      <th>pager</th>\n",
       "      <th>internet</th>\n",
       "      <th>callwait</th>\n",
       "      <th>confer</th>\n",
       "      <th>ebill</th>\n",
       "      <th>loglong</th>\n",
       "      <th>logtoll</th>\n",
       "      <th>lninc</th>\n",
       "      <th>custcat</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.482</td>\n",
       "      <td>3.033</td>\n",
       "      <td>4.913</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.246</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.841</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.401</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>3.807</td>\n",
       "      <td>4.331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.960</td>\n",
       "      <td>3.091</td>\n",
       "      <td>4.382</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>55.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.854</td>\n",
       "      <td>3.199</td>\n",
       "      <td>4.419</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.792</td>\n",
       "      <td>3.332</td>\n",
       "      <td>3.178</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.348</td>\n",
       "      <td>3.168</td>\n",
       "      <td>3.850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.70</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.163</td>\n",
       "      <td>3.866</td>\n",
       "      <td>3.219</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>61.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.824</td>\n",
       "      <td>3.240</td>\n",
       "      <td>5.247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0      11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1      33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2      23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3      38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4       7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "..      ...   ...      ...     ...  ...     ...    ...       ...       ...   \n",
       "195    55.0  44.0     24.0    83.0  1.0    23.0    0.0       1.0       0.0   \n",
       "196    34.0  23.0      3.0    24.0  1.0     7.0    0.0       1.0       0.0   \n",
       "197     6.0  32.0     10.0    47.0  1.0    10.0    0.0       1.0       0.0   \n",
       "198    24.0  30.0      0.0    25.0  4.0     5.0    0.0       1.0       1.0   \n",
       "199    61.0  50.0     16.0   190.0  2.0    22.0    1.0       1.0       1.0   \n",
       "\n",
       "     longmon  ...  pager  internet  callwait  confer  ebill  loglong  logtoll  \\\n",
       "0       4.40  ...    1.0       0.0       1.0     1.0    0.0    1.482    3.033   \n",
       "1       9.45  ...    0.0       0.0       0.0     0.0    0.0    2.246    3.240   \n",
       "2       6.30  ...    0.0       0.0       0.0     1.0    0.0    1.841    3.240   \n",
       "3       6.05  ...    1.0       1.0       1.0     1.0    1.0    1.800    3.807   \n",
       "4       7.10  ...    0.0       0.0       1.0     1.0    0.0    1.960    3.091   \n",
       "..       ...  ...    ...       ...       ...     ...    ...      ...      ...   \n",
       "195    17.35  ...    0.0       0.0       0.0     1.0    0.0    2.854    3.199   \n",
       "196     6.00  ...    0.0       0.0       1.0     1.0    0.0    1.792    3.332   \n",
       "197     3.85  ...    0.0       0.0       1.0     1.0    0.0    1.348    3.168   \n",
       "198     8.70  ...    1.0       1.0       1.0     1.0    1.0    2.163    3.866   \n",
       "199    16.85  ...    0.0       1.0       0.0     0.0    1.0    2.824    3.240   \n",
       "\n",
       "     lninc  custcat  churn  \n",
       "0    4.913      4.0    1.0  \n",
       "1    3.497      1.0    1.0  \n",
       "2    3.401      3.0    0.0  \n",
       "3    4.331      4.0    0.0  \n",
       "4    4.382      3.0    0.0  \n",
       "..     ...      ...    ...  \n",
       "195  4.419      3.0    0.0  \n",
       "196  3.178      3.0    0.0  \n",
       "197  3.850      3.0    0.0  \n",
       "198  3.219      4.0    1.0  \n",
       "199  5.247      2.0    0.0  \n",
       "\n",
       "[200 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../../../data/ChurnData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (pre-processing) –∏ –≤—ã–±–æ—Ä (selection) –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-6221f1cbf25a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['churn'] = df['churn'].astype('int')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "\n",
       "   churn  \n",
       "0      1  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]\n",
    "df['churn'] = df['churn'].astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,  33.,   7., 136.,   5.,   5.,   0.],\n",
       "       [ 33.,  33.,  12.,  33.,   2.,   0.,   0.],\n",
       "       [ 23.,  30.,   9.,  30.,   1.,   2.,   0.],\n",
       "       [ 38.,  35.,   5.,  76.,   2.,  10.,   1.],\n",
       "       [  7.,  35.,  14.,  80.,   2.,  15.,   0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.asarray(df['churn'])\n",
    "y [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.6961288 ,\n",
       "        -0.58477841, -0.85972695],\n",
       "       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -0.6433592 ,\n",
       "        -1.14437497, -0.85972695],\n",
       "       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -1.42318853,\n",
       "        -0.92053635, -0.85972695],\n",
       "       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.6433592 ,\n",
       "        -0.02518185,  1.16316   ],\n",
       "       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.6433592 ,\n",
       "         0.53441472, -0.85972695]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (160, 7) (160,)\n",
      "Test set: (40, 7) (40,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã `sklearn.linear_model.LogisticRegression`\n",
    "\n",
    "`class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)`\n",
    "\n",
    "- `penalty: {\"l1\", \"l2\", \"elasticnet\", \"none\"}, default=\"l2\"`\n",
    "    - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —É–∫–∞–∑–∞–Ω–∏—è –Ω–æ—Ä–º—ã, –ø—Ä–∏–º–µ–Ω—è–µ–º–æ–π –ø—Ä–∏ –Ω–∞–ª–æ–∂–µ–Ω–∏–∏ —à—Ç—Ä–∞—Ñ–æ–≤.\n",
    "    - –†–µ—à–∞—Ç–µ–ª–∏ (`solvers`) `newton-cg`, `sag` –∏ `lbfgs` –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç —Ç–æ–ª—å–∫–æ 12 —à—Ç—Ä–∞—Ñ–æ–≤.\n",
    "    - `elasticnet` –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ä–µ—à–∞—Ç–µ–ª–µ–º `saga`.\n",
    "    - –ï—Å–ª–∏ \"none\" (–Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è `liblinear` —Ä–µ—à–∞—Ç–µ–ª–µ–º), —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è.\n",
    "    - –í –≤–µ—Ä—Å–∏–∏ 0.19: —à—Ç—Ä–∞—Ñ l1 —Å —Ä–µ—à–∞—Ç–µ–ª–µ–º SAGA (–¥–æ–ø—É—Å–∫–∞—é—â–∏–π \"multinomial\" + L1)\n",
    "    \n",
    "- `dual: bool, default=False`\n",
    "    - –î–≤–æ–π–Ω–æ–µ (`dual`) –∏–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–µ (`primal`) –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ (`formulation`).\n",
    "    - –î–≤–æ–π–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è —à—Ç—Ä–∞—Ñ–∞ `l2` —Å `liblinear` —Ä–µ—à–∞—Ç–µ–ª–µ–º.\n",
    "    - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `dual = False`, –∫–æ–≥–¥–∞ `n_samples > n_features`.\n",
    "    \n",
    "- `tol: float, default=1e-4`\n",
    "    - –î–æ–ø—É—Å–∫ –¥–ª—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.\n",
    "    \n",
    "- **`C: float, default=1.0`**\n",
    "    - –û–±—Ä–∞—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–∏–ª—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏.\n",
    "    - –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º —Å –ø–ª–∞–≤–∞—é—â–µ–π –∑–∞–ø—è—Ç–æ–π (`float` > 0).\n",
    "    - –ö–∞–∫ –∏ –≤ [–º–µ—Ç–æ–¥–µ –æ–ø–æ—Ä–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ (support vector machines)](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%BF%D0%BE%D1%80%D0%BD%D1%8B%D1%85_%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BE%D0%B2), –º–µ–Ω—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –±–æ–ª–µ–µ —Å–∏–ª—å–Ω—É—é —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é.\n",
    "    \n",
    "    \n",
    "- `fit_intercept: bool, default=True`\n",
    "    - –£–∫–∞–∑—ã–≤–∞–µ—Ç, —Å–ª–µ–¥—É–µ—Ç –ª–∏ –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É (—Ç–∞–∫–∂–µ –∏–∑–≤–µ—Å—Ç–Ω—É—é –∫–∞–∫ —Å–º–µ—â–µ–Ω–∏–µ (bias) –∏–ª–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ (intercept)) –∫ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è.\n",
    "    \n",
    "    \n",
    "- `intercept_scaling: float, default=1`\n",
    "    - –ü–æ–ª–µ–∑–Ω–æ, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ—à–∞—Ç–µ–ª—å `liblinear` –∏ –¥–ª—è `self.fit_intercept=True`. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ x —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è [x, self.intercept_scaling], —Ç.–µ. —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π (synthetic) –ø—Ä–∏–∑–Ω–∞–∫ —Å –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º, —Ä–∞–≤–Ω—ã–º `intercept_scaling`, –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ –≤–µ–∫—Ç–æ—Ä—É —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ (instance vector).\n",
    "    - –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ä–∞–≤–Ω—ã–º `intercept_scaling * Synthetic_feature_weight.\n",
    "    - –í–ù–ò–ú–ê–ù–ò–ï! –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –≤–µ—Å –ø—Ä–∏–∑–Ω–∞–∫–∞ –ø–æ–¥–ª–µ–∂–∏—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ `l1/l2`, –∫–∞–∫ –∏ –≤—Å–µ –¥—Ä—É–≥–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏. –ß—Ç–æ–±—ã —É–º–µ–Ω—å—à–∏—Ç—å –≤–ª–∏—è–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ –≤–µ—Å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∏, —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –Ω–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ), –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–≤–µ–ª–∏—á–∏—Ç—å `intercept_scaling`.\n",
    "    \n",
    "    \n",
    "- `class_weight: dict –∏–ª–∏ \"balanced\", default=None`\n",
    "    - –í–µ—Å–∞, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∫–ª–∞—Å—Å–∞–º–∏ –≤ —Ñ–æ—Ä–º–µ `{class_label: weight}`.\n",
    "    - –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ –∏–Ω–æ–µ, –≤—Å–µ –∫–ª–∞—Å—Å—ã –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –≤–µ—Å –æ–¥–∏–Ω.\n",
    "    - \"balanced\" —Ä–µ–∂–∏–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è `y` –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∫–∏ –≤–µ—Å–æ–≤, –æ–±—Ä–∞—Ç–Ω–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —á–∞—Å—Ç–æ—Ç–∞–º –∫–ª–∞—Å—Å–æ–≤ –≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ `n_samples / (n_classes * np.bincount (y))`.\n",
    "    - –í–ù–ò–ú–ê–ù–ò–ï! –≠—Ç–∏ –≤–µ—Å–∞ –±—É–¥—É—Ç —É–º–Ω–æ–∂–µ–Ω—ã –Ω–∞ `sample_weight` (–ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π —á–µ—Ä–µ–∑ –º–µ—Ç–æ–¥ `fit`), –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω `sample_weight`.\n",
    "    \n",
    "    \n",
    "- `random_state: int, RandomState instance, default=None`\n",
    "    - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –∫–æ–≥–¥–∞ `solver` == `\"sag\"`, `\"saga\"` –∏–ª–∏ `\"liblinear\"` –¥–ª—è –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "- **`solver{\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"}, default=\"lbfgs\"`**\n",
    "    - –ê–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∑–∞–¥–∞—á–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.\n",
    "    - –î–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö `\"liblinear\"` - —Ö–æ—Ä–æ—à–∏–π –≤—ã–±–æ—Ä, —Ç–æ–≥–¥–∞ –∫–∞–∫ `\"sag\"` –∏ `\"saga\"` –±—ã—Å—Ç—Ä–µ–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö.\n",
    "    - –î–ª—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–æ–≤—ã—Ö –∑–∞–¥–∞—á —Ç–æ–ª—å–∫–æ `\"newton-cg\"`, `\"sag\"`, `\"saga\"` –∏ `\"lbfgs\"` –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏ (multinomial loss). `\"liblinear\"` –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç—Å—è —Å—Ö–µ–º–∞–º–∏ \"–æ–¥–∏–Ω –ø—Ä–æ—Ç–∏–≤ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö\" (one-versus-rest).\n",
    "    - –ó–Ω–∞—á–µ–Ω–∏—è `\"Newton-cg\"`, `\"lbfgs\"`, `\"sag\"` –∏ `\"saga\"` –∏—Å–ø–æ–ª—å–∑—É—é—Ç L2 –∏–ª–∏ –±–µ–∑ —à—Ç—Ä–∞—Ñ–∞.\n",
    "    - `\"liblinear\"` –∏ `\"saga\"` –∏—Å–ø–æ–ª—å–∑—É—é—Ç —à—Ç—Ä–∞—Ñ L1.\n",
    "    - `\"Saga\"` —Ç–∞–∫–∂–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —à—Ç—Ä–∞—Ñ `elasticnet`.\n",
    "    - `\"Liblinear\"` –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫—É `penalty=\"none\"`\n",
    "    \n",
    "- `verbose: int, default=0`\n",
    "    - –î–ª—è —Ä–µ—à–∞—Ç–µ–ª–µ–π `liblinear` –∏ `lbfgs` –º–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å `verbose` –Ω–∞ –ª—é–±–æ–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏.\n",
    "    \n",
    "- `warm_start: bool, default=False`\n",
    "    - –ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ `True`, –ø–æ–≤—Ç–æ—Ä–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –≤—ã–∑–æ–≤–∞ `fit` –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏, –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ –ø—Ä–æ—Å—Ç–æ —É–¥–∞–ª—è–µ—Ç—Å—è –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Ä–µ—à–µ–Ω–∏–µ.\n",
    "    - –ë–µ—Å–ø–æ–ª–µ–∑–µ–Ω –¥–ª—è `–ª–∏–±–ª–∏–Ω–µ–∞—Ä–Ω–æ–≥–æ` —Ä–µ—à–∞—Ç–µ–ª—è.\n",
    "    \n",
    "- `n_jobs: int, default=None`\n",
    "    - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–¥–µ—Ä –¶–ü, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –ø—Ä–∏ —Ä–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏–≤–∞–Ω–∏–∏ –∫–ª–∞—Å—Å–æ–≤, –µ—Å–ª–∏ `multi_class = \"ovr\"`.\n",
    "    - –≠—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è, –µ—Å–ª–∏ —Ä–µ—à–∞—Ç–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ `\"liblinear\"`, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–æ–≥–æ, —É–∫–∞–∑–∞–Ω –ª–∏ `multi_class` –∏–ª–∏ –Ω–µ—Ç.\n",
    "    - `None` –æ–∑–Ω–∞—á–∞–µ—Ç `1`, –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ `joblib.parallel_backend`.\n",
    "    - `-1` –æ–∑–Ω–∞—á–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤.\n",
    "    \n",
    "- `l1_ratio: float, default=None`\n",
    "    - –ü–∞—Ä–∞–º–µ—Ç—Ä Elastic-Net mixing —Å `0 <= l1_ratio <= 1`.\n",
    "    - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ `penalty='elasticnet'`.\n",
    "    - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ `l1_ratio=0` —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é `penalty='l2'`.\n",
    "    - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ `l1_ratio=1` —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é `penalty='l1'`\n",
    "    - –î–ª—è `0 < l1_ratio < 1` —à—Ç—Ä–∞—Ñ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏—é L1 –∏ L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, solver='liblinear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = LR.predict(X_test)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54132919, 0.45867081],\n",
       "       [0.60593357, 0.39406643],\n",
       "       [0.56277713, 0.43722287],\n",
       "       [0.63432489, 0.36567511],\n",
       "       [0.56431839, 0.43568161],\n",
       "       [0.55386646, 0.44613354],\n",
       "       [0.52237207, 0.47762793],\n",
       "       [0.60514349, 0.39485651],\n",
       "       [0.41069572, 0.58930428],\n",
       "       [0.6333873 , 0.3666127 ],\n",
       "       [0.58068791, 0.41931209],\n",
       "       [0.62768628, 0.37231372],\n",
       "       [0.47559883, 0.52440117],\n",
       "       [0.4267593 , 0.5732407 ],\n",
       "       [0.66172417, 0.33827583],\n",
       "       [0.55092315, 0.44907685],\n",
       "       [0.51749946, 0.48250054],\n",
       "       [0.485743  , 0.514257  ],\n",
       "       [0.49011451, 0.50988549],\n",
       "       [0.52423349, 0.47576651],\n",
       "       [0.61619519, 0.38380481],\n",
       "       [0.52696302, 0.47303698],\n",
       "       [0.63957168, 0.36042832],\n",
       "       [0.52205164, 0.47794836],\n",
       "       [0.50572852, 0.49427148],\n",
       "       [0.70706202, 0.29293798],\n",
       "       [0.55266286, 0.44733714],\n",
       "       [0.52271594, 0.47728406],\n",
       "       [0.51638863, 0.48361137],\n",
       "       [0.71331391, 0.28668609],\n",
       "       [0.67862111, 0.32137889],\n",
       "       [0.50896403, 0.49103597],\n",
       "       [0.42348082, 0.57651918],\n",
       "       [0.71495838, 0.28504162],\n",
       "       [0.59711064, 0.40288936],\n",
       "       [0.63808839, 0.36191161],\n",
       "       [0.39957895, 0.60042105],\n",
       "       [0.52127638, 0.47872362],\n",
       "       [0.65975464, 0.34024536],\n",
       "       [0.5114172 , 0.4885828 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_prob = LR.predict_proba(X_test)\n",
    "y_predicted_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ (Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  9]\n",
      " [ 1 24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix_(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "print(confusion_matrix(y_test, y_predicted, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 6  9]\n",
      " [ 1 24]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_predicted, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix_(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(LR, X_test, y_test)  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83        25\n",
      "           1       0.86      0.40      0.55        15\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.79      0.68      0.69        40\n",
      "weighted avg       0.78      0.75      0.72        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the count of each section, we can calculate precision and recall of each label:\n",
    "\n",
    "-   **Precision** is a measure of the accuracy provided that a class label has been predicted. It is defined by: precision = TP¬†/¬†(TP¬†+¬†FP)\n",
    "\n",
    "-   **Recall** is true positive rate. It is defined as: Recall = ¬†TP¬†/¬†(TP¬†+¬†FN)\n",
    "\n",
    "So, we can calculate precision and recall of each class.\n",
    "\n",
    "**F1 score:**\n",
    "Now we are in the position to calculate the F1 scores for each label based on the precision and recall of that label. \n",
    "\n",
    "The F1 score is the harmonic average of the¬†precision and recall, where an F1¬†score reaches its best value at 1 (perfect precision and recall) and worst at 0. It is a good way to show that a classifier has a good value for both recall and precision.\n",
    "\n",
    "Finally, we can tell the average accuracy for this classifier is the average of the F1-score for both labels, which is 0.72 in our case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log loss\n",
    "\n",
    "Now, lets try **log loss** for evaluation. In logistic regression, the output can be the probability of customer churn is yes (or equals to 1). This probability is a value between 0 and 1.\n",
    "Log loss(¬†Logarithmic¬†loss) measures the performance of a¬†classifier¬†where the predicted output is a probability value between 0 and 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6017092478101185"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, y_predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss: : 0.61\n"
     ]
    }
   ],
   "source": [
    "LR2 = LogisticRegression(C=0.01, solver='sag').fit(X_train,y_train)\n",
    "y_predicted_prob2 = LR2.predict_proba(X_test)\n",
    "print (\"LogLoss: : %.2f\" % log_loss(y_test, y_predicted_prob2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LevelUp_DataScience] *",
   "language": "python",
   "name": "conda-env-LevelUp_DataScience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
