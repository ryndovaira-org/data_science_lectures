{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Источники:**\n",
    "\n",
    "[XGBoost](https://neerc.ifmo.ru/wiki/index.php?title=XGBoost)\n",
    "\n",
    "[Виды ансамблей](https://neerc.ifmo.ru/wiki/index.php?title=%D0%92%D0%B8%D0%B4%D1%8B_%D0%B0%D0%BD%D1%81%D0%B0%D0%BC%D0%B1%D0%BB%D0%B5%D0%B9)\n",
    "\n",
    "[XGBoost Parameters](https://xgboost.readthedocs.io/en/latest/parameter.html)\n",
    "\n",
    "[Эвристический алгоритм](https://ru.wikipedia.org/wiki/%D0%AD%D0%B2%D1%80%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC#:~:text=%D0%AD%D0%B2%D1%80%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%20(%D1%8D%D0%B2%D1%80%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0)%20%E2%80%94%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC,%D1%80%D0%B5%D1%88%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%BD%D0%B5%20%D0%BC%D0%BE%D0%B6%D0%B5%D1%82%20%D0%B1%D1%8B%D1%82%D1%8C%20%D0%BD%D0%B0%D0%B9%D0%B4%D0%B5%D0%BD%D0%BE.)\n",
    "\n",
    "[Настройка параметров XGBoost](https://russianblogs.com/article/2308221344)\n",
    "\n",
    "[Python API Reference](https://xgboost.readthedocs.io/en/latest/python/python_api.html)\n",
    "\n",
    "[Chapter 12 Gradient Boosting](https://bradleyboehmke.github.io/HOML/gbm.html)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка окружения"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ВНИМАНИЕ: необходимо удостовериться, что виртуальная среда выбрана правильно!\n",
    "\n",
    "# Для MacOS/Ubuntu\n",
    "# !which pip\n",
    "\n",
    "# Для Windows\n",
    "# !where pip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !conda install matplotlib numpy scikit-learn seaborn -y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Загрузка данных\n",
    "\n",
    "[Источник (FuelConsumption)](https://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./../../data/FuelConsumptionCo2.csv\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Разделение данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['CO2EMISSIONS'].copy()\n",
    "X = df[['ENGINESIZE']].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Одна из самых популярных и эффективных реализаций алгоритма градиентного бустинга на деревьях на 2019-й год.**\n",
    "\n",
    "\n",
    "В основе XGBoost лежит алгоритм градиентного бустинга деревьев решений. \n",
    "\n",
    "**Градиентный бустинг** — это техника машинного обучения для задач классификации и регрессии, которая строит модель предсказания в форме ансамбля слабых предсказывающих моделей, обычно деревьев решений. Обучение ансамбля проводится последовательно в отличие, например от бэггинга. \n",
    "\n",
    "**Ансамбль алгоритмов (методов)** — метод, который использует несколько обучающих алгоритмов с целью получения лучшей эффективности прогнозирования, чем можно было бы получить от каждого обучающего алгоритма по отдельности.\n",
    "\n",
    "На каждой итерации вычисляются отклонения предсказаний уже обученного ансамбля на обучающей выборке. Следующая модель, которая будет добавлена в ансамбль будет предсказывать эти отклонения. Таким образом, добавив предсказания нового дерева к предсказаниям обученного ансамбля мы можем уменьшить среднее отклонение модели, котрое является таргетом оптимизационной задачи. Новые деревья добавляются в ансамбль до тех пор, пока ошибка уменьшается, либо пока не выполняется одно из правил \"ранней остановки\".\n",
    "\n",
    "\n",
    "XGBoost поддерживает все возможности таких библиотек как scikit-learn с возможностью добавлять регуляризацию. Поддержаны три главные формы градиетного бустинга:\n",
    "\n",
    "- Стандартный градиентный бустинг с возможностью изменения скорости обучения(learning rate).\n",
    "- Стохастический градиентный бустинг с возможностью семплирования по строкам и колонкам датасета.\n",
    "- Регуляризованный градиентный бустинг с L1 и L2 регуляризацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделить независимую и зависимую переменные / train и test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['CO2EMISSIONS'].copy()\n",
    "X = df.drop(['CO2EMISSIONS', 'MAKE', 'MODEL', 'VEHICLECLASS', 'TRANSMISSION', 'FUELTYPE'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `class xgboost.XGBRegressor(**kwargs)`\n",
    "\n",
    "**[Остальные параметры см. 7_2_xgboost_params](./7_2_xgboost_params.ipynb)**\n",
    "\n",
    "- **`n_estimators (int)`**\n",
    "    - Количество деревьев с градиентным усилением. Эквивалентно количеству раундов boost-инга (boosting rounds).\n",
    "\n",
    "- **`max_depth (int) [default=6]`**\n",
    "    - Максимальная глубина дерева. Увеличение этого значения сделает модель более сложной и с большей вероятностью переобучится (overfit).\n",
    "    - Допустимые значения: $[0, \\infty]$, `0` принимается только в lossguided для роста, когда tree_method установлен как hist и указывает отсутствие ограничения на глубину. Помните, что XGBoost агрессивно расходует память при обучении глубокого дерева.\n",
    "\n",
    "- **`learning_rate (float) [default=0.3, alias: eta]`**\n",
    "    - Уменьшение размера шага, используемое в обновлении, чтобы **предотвратить переобучение (overfitting)**. После каждого шага повышения мы можем напрямую получить веса новых функций, а eta уменьшает веса функций, чтобы сделать процесс повышения более консервативным.\n",
    "    - Допустимые значения: $[0, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-fe0d8d02009e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# импортировать пакет xgboost\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mxgboost\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mxg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# создать объект XGBRegressor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mxgb_r\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mxg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mXGBRegressor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_estimators\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_depth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# импортировать пакет xgboost\n",
    "import xgboost as xg\n",
    "\n",
    "# создать объект XGBRegressor\n",
    "xgb_r = xg.XGBRegressor(n_estimators = 10, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fit(X, y, *, sample_weight=None, base_margin=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, feature_weights=None, callbacks=None)`\n",
    "\n",
    "**[Остальные параметры см. 7_2_xgboost_params](./7_2_xgboost_params.ipynb)**\n",
    "\n",
    "- **`X (array_like)`** - Матрица признаков.\n",
    "    \n",
    "    \n",
    "- **`y (array_like)`** - Labels (\"правильные ответы\").\n",
    "\n",
    "\n",
    "- **`early_stopping_rounds (int)`** \n",
    "    - Активирует раннюю остановку.\n",
    "    - Чтобы продолжить обучение, показатель валидации должен улучшаться хотя бы раз в каждом раунде `early_stopping_rounds`.\n",
    "    - Требуется хотя бы один элемент в `eval_set`.\n",
    "    - Метод возвращает модель с последней итерации (а не самой лучшей).\n",
    "    - Если в `eval_set` более одного элемента, для ранней остановки будет использоваться *последняя запись* (last entry).\n",
    "    - Если в `eval_metric` более одной метрики, для ранней остановки будет использоваться *последняя метрика* (last metric).\n",
    "    - Если произойдет ранняя остановка, модель будет иметь три дополнительных поля: `clf.best_score`, `clf.best_iteration` и `clf.best_ntree_limit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучить модель\n",
    "xgb_r.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества модели (Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `predict(data, output_margin=False, ntree_limit=None, validate_features=True, base_margin=None)`\n",
    "\n",
    "**[Остальные параметры см. 7_2_xgboost_params](./7_2_xgboost_params.ipynb)**\n",
    "\n",
    "- **`data (numpy.array/scipy.sparse)`**\n",
    "    - Данные для прогнозирования.\n",
    "    \n",
    "    \n",
    "- **`validate_features (bool)`**\n",
    "    - Если это `True`, то будет произведена проверка (validate), что `feature_names` для `Booster` и `data` идентичны. В противном случае предполагается, что `feature_names` совпадают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# использовать обученную модель для предсказания на test выборке\n",
    "y_predicted = xgb_r.predict(X_test)\n",
    "\n",
    "# вывести результаты предсказания\n",
    "print(f'Variance score: {xgb_r.score(X_test, y_test)}')    # Coefficient of determination R^2 of the prediction\n",
    "print(f\"Residual sum of squares: {np.mean((y_predicted - y_test) ** 2)}\")    # MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_true=y_test, y_pred=y_predicted)    # эквивалентно simple_regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# MSE\n",
    "mean_squared_error(y_test, y_predicted, squared=True)   # эквивалентно np.mean((y_predicted - y_test) ** 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}