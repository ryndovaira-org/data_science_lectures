{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Источники:**\n",
    "\n",
    "[XGBoost](https://neerc.ifmo.ru/wiki/index.php?title=XGBoost)\n",
    "\n",
    "[Виды ансамблей](https://neerc.ifmo.ru/wiki/index.php?title=%D0%92%D0%B8%D0%B4%D1%8B_%D0%B0%D0%BD%D1%81%D0%B0%D0%BC%D0%B1%D0%BB%D0%B5%D0%B9)\n",
    "\n",
    "[XGBoost Parameters](https://xgboost.readthedocs.io/en/latest/parameter.html)\n",
    "\n",
    "[Эвристический алгоритм](https://ru.wikipedia.org/wiki/%D0%AD%D0%B2%D1%80%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC#:~:text=%D0%AD%D0%B2%D1%80%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%20(%D1%8D%D0%B2%D1%80%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0)%20%E2%80%94%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC,%D1%80%D0%B5%D1%88%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%BD%D0%B5%20%D0%BC%D0%BE%D0%B6%D0%B5%D1%82%20%D0%B1%D1%8B%D1%82%D1%8C%20%D0%BD%D0%B0%D0%B9%D0%B4%D0%B5%D0%BD%D0%BE.)\n",
    "\n",
    "[Настройка параметров XGBoost](https://russianblogs.com/article/2308221344)\n",
    "\n",
    "[Python API Reference](https://xgboost.readthedocs.io/en/latest/python/python_api.html)\n",
    "\n",
    "[Chapter 12 Gradient Boosting](https://bradleyboehmke.github.io/HOML/gbm.html)\n",
    "\n",
    "[One-Hot Encoding is making your Tree-Based Ensembles worse, here’s why?](https://towardsdatascience.com/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769#%3A~%3Atext%3DOne-hot%20encoding%20categorical%20variables%2Cimportance%20resulting%20in%20poorer%20performance)\n",
    "\n",
    "[Why is XGBoost better than Random Forest?](https://www.quora.com/Why-is-XGBoost-better-than-Random-Forest)\n",
    "\n",
    "[CatBoost vs. Light GBM vs. XGBoost](https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ВНИМАНИЕ: необходимо удостовериться, что виртуальная среда выбрана правильно!\n",
    "\n",
    "# Для MacOS/Ubuntu\n",
    "# !which pip\n",
    "\n",
    "# Для Windows\n",
    "# !where pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !conda install matplotlib numpy scikit-learn seaborn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge shap -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.39.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "shap.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "\n",
    "[Источник (Calculate Concrete Strength)](https://www.kaggle.com/prathamtripathi/regression-with-neural-networking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0      540.0                 0.0      0.0  162.0               2.5   \n",
       "1      540.0                 0.0      0.0  162.0               2.5   \n",
       "2      332.5               142.5      0.0  228.0               0.0   \n",
       "3      332.5               142.5      0.0  228.0               0.0   \n",
       "4      198.6               132.4      0.0  192.0               0.0   \n",
       "...      ...                 ...      ...    ...               ...   \n",
       "1025   276.4               116.0     90.3  179.6               8.9   \n",
       "1026   322.2                 0.0    115.6  196.0              10.4   \n",
       "1027   148.5               139.4    108.6  192.7               6.1   \n",
       "1028   159.1               186.7      0.0  175.6              11.3   \n",
       "1029   260.9               100.5     78.3  200.6               8.6   \n",
       "\n",
       "      Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0               1040.0           676.0   28     79.99  \n",
       "1               1055.0           676.0   28     61.89  \n",
       "2                932.0           594.0  270     40.27  \n",
       "3                932.0           594.0  365     41.05  \n",
       "4                978.4           825.5  360     44.30  \n",
       "...                ...             ...  ...       ...  \n",
       "1025             870.1           768.3   28     44.28  \n",
       "1026             817.9           813.4   28     31.18  \n",
       "1027             892.4           780.0   28     23.70  \n",
       "1028             989.6           788.9   28     32.77  \n",
       "1029             864.5           761.5   28     32.40  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../../data/concrete_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение данных на `X` и `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Strength'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[target].copy()\n",
    "X = df.drop(columns=[target]).copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
       "       'Coarse Aggregate', 'Fine Aggregate', 'Age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_arr = X_train.columns\n",
    "feature_names_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cement',\n",
       " 'Blast Furnace Slag',\n",
       " 'Fly Ash',\n",
       " 'Water',\n",
       " 'Superplasticizer',\n",
       " 'Coarse Aggregate',\n",
       " 'Fine Aggregate',\n",
       " 'Age']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = feature_names_arr.to_list()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание\n",
    "\n",
    "**XGBoost** (e**X**treme **G**radient **Boost**ing) является оптимизированной версией алгоритма Gradient Boosting.\n",
    "\n",
    "**Одна из самых популярных и эффективных реализаций алгоритма градиентного бустинга на деревьях на 2019-й год.**\n",
    "\n",
    "\n",
    "В основе XGBoost лежит алгоритм градиентного бустинга деревьев решений. \n",
    "\n",
    "**Градиентный бустинг** — это техника машинного обучения для задач **классификации** и **регрессии**, которая строит модель предсказания в форме ансамбля слабых предсказывающих моделей, обычно **деревьев решений**. Обучение ансамбля проводится последовательно в отличие, например от бэггинга. \n",
    "\n",
    "**Ансамбль алгоритмов (методов)** — метод, который использует несколько обучающих алгоритмов с целью получения лучшей эффективности прогнозирования, чем можно было бы получить от каждого обучающего алгоритма по отдельности.\n",
    "\n",
    "На каждой итерации вычисляются отклонения предсказаний уже обученного ансамбля на обучающей выборке. Следующая модель, которая будет добавлена в ансамбль будет предсказывать эти отклонения. Таким образом, добавив предсказания нового дерева к предсказаниям обученного ансамбля мы можем уменьшить среднее отклонение модели, котрое является таргетом оптимизационной задачи. Новые деревья добавляются в ансамбль до тех пор, пока ошибка уменьшается, либо пока не выполняется одно из правил \"ранней остановки\".\n",
    "\n",
    "Реализация алгоритма была разработана для эффективности вычислительных ресурсов времени и памяти. Цель проекта заключалась в том, чтобы наилучшим образом использовать имеющиеся ресурсы для обучения модели. Некоторые ключевые функции реализации алгоритма включают:\n",
    "- Различные стратегии обработки пропущенных данных.\n",
    "- Блочная структура для поддержки распараллеливания обучения деревьев.\n",
    "- Продолжение обучения для дообучения на новых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Особенности модели\n",
    "\n",
    "XGBoost поддерживает все возможности таких библиотек как scikit-learn с возможностью добавлять регуляризацию. Поддержаны **три главные формы градиетного бустинга**:\n",
    "- Стандартный градиентный бустинг с возможностью изменения скорости обучения (learning rate).\n",
    "- Стохастический градиентный бустинг с возможностью семплирования по строкам и колонкам датасета.\n",
    "- Регуляризованный градиентный бустинг с L1 и L2 регуляризацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Системные функции\n",
    "\n",
    "Библиотека предоставляет систему для использования в различных вычислительных средах:\n",
    "\n",
    "- Параллелизация построения дерева с использованием всех ваших ядер процессора во время обучения.\n",
    "- Распределенные вычисления для обучения очень крупных моделей с использованием кластера машин.\n",
    "- Вычисления для очень больших наборов данных, которые не вписываются в память.\n",
    "- Кэш Оптимизация структуры данных и алгоритма для наилучшего использования аппаратного обеспечения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекомендации\n",
    "\n",
    "- Незаметная слабая сторона XGBoost: модель преобразует категориальные переменные в One Hot Encoding (OHE). Как правило One-Hot Encoding ухудшает древовидные ансамбли.\n",
    "\n",
    "- Если у вас много категориальных переменных, лучшим выбором будет CatBoost или Light GBM.\n",
    "\n",
    "- Одна приятная особенность деревьев (XGBoost, Random Forest и т.д.) заключается в том, что не нужно нормализовать свои признаки, как это следует делать, например, с SVM.\n",
    "\n",
    "- Деревья также хорошо справляются, если данные являются \"lumpy\", то есть немонотонные.\n",
    "\n",
    "- Еще одна проблема с деревьями, на которые стоит обратить внимание, - они могут переобучиться. Если настроить параметры так, чтобы деревья оказались слишком глубокими, то с зашумленными данными, вероятно, получится переобученная модель.\n",
    "\n",
    "- Нет никаких конкретных доказательств того, что XGBoost работает намного лучше, чем Random Forest, но на практике это как правило так."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature importances via coefficients')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso = LassoCV().fit(X_train, y_train)\n",
    "importance = np.abs(lasso.coef_)\n",
    "\n",
    "plt.bar(height=importance, x=feature_names)\n",
    "plt.xticks(rotation=60)\n",
    "plt.title(\"Feature importances via coefficients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "sfs_forward = SequentialFeatureSelector(lasso, \n",
    "                                        n_features_to_select=5,\n",
    "                                        direction='forward').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True,  True, False, False,  True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs_forward.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cement', 'Blast Furnace Slag', 'Water', 'Superplasticizer', 'Age'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_selected = feature_names_arr[sfs_forward.get_support()]\n",
    "feat_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели (Train) - pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Важные параметры `xgboost.XGBRegressor`\n",
    "\n",
    "- **`n_estimators (int)`**\n",
    "    - Количество деревьев с градиентным усилением. Эквивалентно количеству раундов boost-инга (boosting rounds).\n",
    "\n",
    "- **`max_depth (int) [default=6]`**\n",
    "    - Максимальная глубина дерева. Увеличение этого значения сделает модель более сложной и с большей вероятностью переобучится (overfit).\n",
    "    - Допустимые значения: $[0, \\infty]$, `0` принимается только в lossguided для роста, когда tree_method установлен как hist и указывает отсутствие ограничения на глубину. Помните, что XGBoost агрессивно расходует память при обучении глубокого дерева.\n",
    "\n",
    "- **`learning_rate (float) [default=0.3, alias: eta]`**\n",
    "    - Уменьшение размера шага, используемое в обновлении, чтобы **предотвратить переобучение (overfitting)**. После каждого шага повышения мы можем напрямую получить веса новых функций, а eta уменьшает веса функций, чтобы сделать процесс повышения более консервативным.\n",
    "    - Допустимые значения: $[0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Важные параметры `fit`\n",
    "\n",
    "- **`X (array_like)`** - Матрица признаков.\n",
    "    \n",
    "\n",
    "- **`y (array_like)`** - Labels (\"правильные ответы\").\n",
    "\n",
    "\n",
    "- **`early_stopping_rounds (int)`** \n",
    "    - Активирует раннюю остановку.\n",
    "    - Чтобы продолжить обучение, показатель валидации должен улучшаться хотя бы раз в каждом раунде `early_stopping_rounds`.\n",
    "    - Требуется хотя бы один элемент в `eval_set`.\n",
    "    - Метод возвращает модель с последней итерации (а не самой лучшей).\n",
    "    - Если в `eval_set` более одного элемента, для ранней остановки будет использоваться *последняя запись* (last entry).\n",
    "    - Если в `eval_metric` более одной метрики, для ранней остановки будет использоваться *последняя метрика* (last metric).\n",
    "    - Если произойдет ранняя остановка, модель будет иметь три дополнительных поля: `clf.best_score`, `clf.best_iteration` и `clf.best_ntree_limit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'model__max_depth': [3, 5, 8], \n",
    "              'model__n_estimators': [10, 250, 500, 900], \n",
    "              'model__learning_rate': [0.05, 0.35]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('passthrough', 'passthrough', feat_selected.to_list())\n",
    "    ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "\n",
    "pipeline = Pipeline(steps = [\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', xg.XGBRegressor())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gs = GridSearchCV(pipeline, param_grid, scoring='neg_mean_squared_error', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"best_params: {model_gs.best_params_}\")\n",
    "print(f\"best_score: {model_gs.best_score_:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества модели (Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = model_gs.predict(X_test)\n",
    "y_train_predicted = model_gs.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'R2 (train): {r2_score(y_train, y_train_predicted)}')\n",
    "print(f'R2 (test): {r2_score(y_test, y_test_predicted)}')\n",
    "\n",
    "print(f\"MSE (train): {mean_squared_error(y_train, y_train_predicted, squared=True)}\")\n",
    "print(f\"MSE (test): {mean_squared_error(y_test, y_test_predicted, squared=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Важность признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost [Plotting API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gs.best_estimator_['model'].get_booster().feature_names = feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg.plot_importance(model_gs.best_estimator_['model'].get_booster(), height=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [SHAP](https://github.com/slundberg/shap)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choosen_instance = X_train.iloc[[1]]\n",
    "choosen_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(choosen_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_values[0], choosen_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Параметры XGBRegressor для Python Scikit-Learn API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `class xgboost.XGBRegressor(**kwargs)`\n",
    "\n",
    "- **`n_estimators (int)`**\n",
    "    - Количество деревьев с градиентным усилением. Эквивалентно количеству раундов boost-инга (boosting rounds).\n",
    "\n",
    "\n",
    "- **`max_depth (int) [default=6]`**\n",
    "    - Максимальная глубина дерева. Увеличение этого значения сделает модель более сложной и с большей вероятностью переобучится (overfit).\n",
    "    - Допустимые значения: $[0, \\infty]$, `0` принимается только в `lossguided` для роста, когда `tree_method` установлен как hist и указывает отсутствие ограничения на глубину. Помните, что XGBoost агрессивно расходует память при обучении глубокого дерева.\n",
    "\n",
    "\n",
    "- **`learning_rate (float) [default=0.3, alias: eta]`**\n",
    "    - Уменьшение размера шага, используемое в обновлении, чтобы **предотвратить переобучение (overfitting)**. После каждого шага повышения мы можем напрямую получить веса новых функций, а eta уменьшает веса функций, чтобы сделать процесс повышения более консервативным.\n",
    "    - Допустимые значения: $[0, 1]$\n",
    "\n",
    "\n",
    "- **`subsample (float) [default=1]`**\n",
    "    - Соотношение подвыборки обучающих примеров. Установка его на `0.5` означает, что XGBoost будет случайным образом выбирать половину обучающих данных перед выращиванием деревьев. И это *предотвратит переобучение (overfitting)*.\n",
    "    - Подвыборка (subsample) будет выполняться один раз на каждой итерации boosting-а.\n",
    "    - Допустимые значения: $(0, 1]$\n",
    "\n",
    "\n",
    "- `verbosity  (int) [default=1]`\n",
    "    - Детальность печатных сообщений.\n",
    "    - Допустимые значения:\n",
    "        - 0 (silent)\n",
    "        - 1 (warning)\n",
    "        - 2 (info)\n",
    "        - 3 (debug)\n",
    "    - Иногда XGBoost пытается изменить конфигурации на основе эвристики, что отображается как предупреждающее сообщение. Если происходит неожиданное поведение, попробуйте увеличить значение подробности.\n",
    "    - *Эвристический алгоритм (эвристика) — алгоритм решения задачи, включающий практический метод, не являющийся гарантированно точным или оптимальным, но достаточный для решения поставленной задачи. Позволяет ускорить решение задачи в тех случаях, когда точное решение не может быть найдено.\n",
    "\n",
    "\n",
    "- `objective (string | callable)`\n",
    "    - Устанавливает задачу обучения (learning task) и соответствующую цель обучения (learning objective) или настраиваемую целевую функцию (objective function), которая будет использоваться.\n",
    "    - В этом случае objective parameter должен иметь сигнатуру `(y_true, y_pred) -> grad, hess`\n",
    "        - `y_true: array_like of shape [n_samples]` - Целевые значения\n",
    "        - `y_pred: array_like of shape [n_samples]` - Прогнозируемые значения\n",
    "        - `grad: array_like of shape [n_samples]`- Значение градиента для каждой точки выборки.\n",
    "        - `hess: array_like of shape [n_samples]` - Значение второй производной для каждой точки выборки\n",
    "\n",
    "\n",
    "- `booster (string) [default='gbtree']`\n",
    "    - Какой booster использовать.\n",
    "    - Допустимые значения:\n",
    "        - `gbtree`\n",
    "        - `gblinear`\n",
    "        - `dart`\n",
    "    - `gbtree` и `dart` используют модели на основе дерева (tree based models), в то время как `gblinear` использует линейные функции (linear functions).\n",
    "\n",
    "\n",
    "- `tree_method (string) [default='auto']`\n",
    "    - Алгоритм построения дерева, используемый в XGBoost.\n",
    "    - XGBoost поддерживает `approx`, `hist` и `gpu_hist` для распределенного обучения. Экспериментальная поддержка внешней памяти доступна для `approx` и `gpu_hist`.\n",
    "    - Допустимые значения: `auto`, `exact`, `approx`, `hist`, `gpu_hist`, это комбинация часто используемых средств обновления. Для других средств обновления, таких как `refresh`, установите параметр `updater` напрямую.\n",
    "        - `auto`: Использует эвристику, чтобы выбрать самый быстрый метод.\n",
    "            - Для большего набора данных будет выбран `approx`. Рекомендуется попробовать `hist` и `gpu_hist` для повышения производительности с большим набором данных. `gpu_hist` поддерживает внешнюю память.\n",
    "            - Поскольку старое поведение всегда использует точную жадность ([exact greedy](https://medium.com/analytics-vidhya/boosting-models-unwrapping-the-basic-exact-greedy-algorithm-b67d88c7189a)) на одной машине, пользователь получит сообщение, когда будет выбран `approx` алгоритм для уведомления об этом выборе.\n",
    "        - `exact`: Точный жадный алгоритм ([exact greedy](https://medium.com/analytics-vidhya/boosting-models-unwrapping-the-basic-exact-greedy-algorithm-b67d88c7189a)). Перечисляет всех отдельных кандидатов.\n",
    "        - `approx`: Приблизительный жадный алгоритм ([approximate greedy](https://towardsdatascience.com/why-xgboost-is-so-effective-3a193951e289)) с использованием квантилей ([quantile sketch](https://datasketches.apache.org/docs/Quantiles/QuantilesOverview.html)) и гистограммы градиента.\n",
    "        - `hist`: Более быстрый приближенный жадный алгоритм Приблизительный жадный алгоритм ([approximate greedy](https://towardsdatascience.com/why-xgboost-is-so-effective-3a193951e289)), оптимизированный для гистограммы.\n",
    "        - `gpu_hist`: Реализация алгоритма `hist` на GPU.\n",
    "\n",
    "\n",
    "- `n_jobs (int)`\n",
    "    - Количество параллельных потоков, используемых для запуска `xgboost`.\n",
    "    - При использовании с другими алгоритмами Scikit-Learn, такими как `grid search`, можно выбрать, какой алгоритм распараллеливать и балансировать потоки.\n",
    "    - Создание конкуренции потоков ([thread contention](https://stackoverflow.com/questions/1970345/what-is-thread-contention#:~:text=Essentially%20thread%20contention%20is%20a,has%20unlocked%20that%20particular%20object.)) значительно замедлит работу обоих алгоритмов.\n",
    "\n",
    "\n",
    "- `gamma (float) [default=0, alias: min_split_loss]`\n",
    "    - Минимальное изменение значения функции потерь (Minimum loss reduction), необходимое для дальнейшего разбиения листового узла (leaf node) дерева (tree), то есть разделение листа на поддеревья. Чем больше `gamma`, тем более \"консервативным\" будет алгоритм.\n",
    "    - Допустимые значения: $[0, \\infty]$\n",
    "\n",
    "\n",
    "- `min_child_weight (float) [default=1]`\n",
    "    - Минимальная сумма веса экземпляра (hessian), необходимая для дочернего узла (child). Если на этапе разбиения дерева получается листовой узел (leaf node) с суммой веса экземпляра меньше min_child_weight, то процесс построения откажется от дальнейшего разделения.\n",
    "    - В задаче линейной регрессии (linear regression) это просто соответствует минимальному количеству экземпляров (instances), которое должно быть в каждом узле. Чем больше min_child_weight, тем более \"консервативным\": будет алгоритм.\n",
    "    - Допустимые значения: $[0, \\infty]$\n",
    "\n",
    "\n",
    "- `max_delta_step (int) [default=0]`\n",
    "    - Максимальный шаг дельты, который допускается на выходе каждого листа (leaf output) для оценки веса каждого дерева.\n",
    "    - Если значение установлено на `0`, это означает, что ограничения нет.\n",
    "    - Если для него установлено `положительное значение`, это может помочь сделать шаг обновления более \"консервативным\".\n",
    "    - *Обычно этот параметр не нужен*, но он может помочь в логистической регрессии (logistic regression), когда класс крайне несбалансирован (imbalanced).\n",
    "    - Установка значения 1-10 может помочь контролировать обновление.\n",
    "    - Допустимые значения: $[0, 1]$\n",
    "\n",
    "\n",
    "- `colsample_bytree, colsample_bylevel, colsample_bynode (float)[default=1]`\n",
    "    - Это семейство параметров для подвыборки столбцов.\n",
    "    - Все параметры `colsample_by*` имеют диапазон `(0, 1]`, значение по умолчанию 1, и определяют долю столбцов, подлежащих подвыборке.\n",
    "    - `colsample_bytree` - это соотношение столбцов подвыборки при построении каждого дерева. Подвыборка (subsampling) выполняется один раз для каждого построенного дерева.\n",
    "    - `colsample_bylevel` - отношение подвыборки столбцов для каждого уровня. Подвыборка (subsampling) выполняется один раз для каждого нового уровня глубины, достигнутого в дереве. Столбцы выбираются из набора столбцов, выбранных для *текущего дерева*.\n",
    "    - `colsample_bynode` - это отношение подвыборки столбцов для каждого узла (разбиение). Подвыборка (subsampling) происходит каждый раз при оценке нового разделения. Столбцы выбираются из набора столбцов, выбранных для *текущего уровня*.\n",
    "    - `colsample_by*` параметры работают [кумулятивно (накопительно)](https://ru.wiktionary.org/wiki/%D0%BA%D1%83%D0%BC%D1%83%D0%BB%D1%8F%D1%82%D0%B8%D0%B2%D0%BD%D1%8B%D0%B9). Например, комбинация `{'colsample_bytree':0.5, 'colsample_bylevel':0.5, 'colsample_bynode':0.5}` с 64 признаками оставит 8 признаков на выбор в каждом сплите (split).\n",
    "    - В интерфейсе Python при использовании метода `hist`, `gpu_hist` или `exact` методов дерева (tree method) можно установить `feature_weights` для DMatrix, чтобы определить вероятность выбора каждой функции при использовании выборки столбцов (column sampling). Аналогичный параметр для метода `fit` есть в интерфейсе sklearn.\n",
    "\n",
    "\n",
    "- `reg_alpha (float) [default=0, alias: alpha]`\n",
    "    - Элемент регуляризации L1 ([lasso regression](http://www.machinelearning.ru/wiki/index.php?title=%D0%9B%D0%B0%D1%81%D1%81%D0%BE)) на весах.\n",
    "    - Увеличение этого значения сделает модель более \"консервативной\".\n",
    "\n",
    "- `reg_lambda (float) [default=1, alias: lambda]`\n",
    "    - Условие L2 регуляризации ([ridge regression или Tikhonov regularization](http://www.machinelearning.ru/wiki/index.php?title=%D0%A0%D0%B8%D0%B4%D0%B6-%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F)) весов.\n",
    "    - Увеличение этого значения сделает модель более \"консервативной\".\n",
    "\n",
    "\n",
    "- `scale_pos_weight (float) [default=1]`\n",
    "    - Контролирует баланс положительных и отрицательных весов, что полезно для несбалансированных классов.\n",
    "    - Типичное значение, которое следует учитывать: `sum(negative instances) / sum(positive instances)`.\n",
    "\n",
    "\n",
    "- `base_score (float) [default=0.5]`\n",
    "    - Начальная оценка прогноза для всех экземпляров, глобальный bias.\n",
    "    - При достаточном количестве итераций изменение этого значения не будет иметь большого эффекта.\n",
    "\n",
    "\n",
    "- `random_state (int)`\n",
    "    - Начальное число (порождающий элемент) для генератора случайных чисел ([random seed](https://en.wikipedia.org/wiki/Random_seed)).\n",
    "    - xgboost использует генератор случайных чисел (random generator) только для подвыборки (subsampling). В остальном поведение детерминировано.\n",
    "\n",
    "\n",
    "- `missing (float) [default=np.nan]`\n",
    "    - Значение, которое должны быть использовано в качестве пропущенных значений (missing value).\n",
    "\n",
    "\n",
    "- `num_parallel_tree (int) [default=1] `\n",
    "    - Количество параллельных деревьев (trees), построенных на каждой итерации.\n",
    "    - Эта опция используется для поддержки boosting-а случайного леса (random forest).\n",
    "\n",
    "\n",
    "- `monotone_constraints (str)`\n",
    "    - Ограничение переменной монотонности.\n",
    "\n",
    "\n",
    "- `interaction_constraints (str)`\n",
    "    - Ограничение для взаимодействия, представляющие разрешенные взаимодействия.\n",
    "    - Ограничения должны быть указаны в виде списка вложений, например `[[0, 1], [2, 3, 4]]`, где каждый внутренний список представляет собой группу индексов функций, которым разрешено взаимодействовать друг с другом.\n",
    "\n",
    "\n",
    "- `importance_type (string) [default=\"gain\"]`\n",
    "    - Тип важности признака для свойства `feature_importances_`:.\n",
    "    - Допустимые значения: `\"gain\"`, `\"weight\"`, `\"cover\"`, `\"total_gain\"` или `\"total_cover\"`.\n",
    "\n",
    "\n",
    "- `**kwargs (dict, optional)`\n",
    "    - `**kwargs` для объекта XGBoost Booster. Полную документацию по параметрам можно найти [здесь](https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst).\n",
    "    - `**kwargs` не поддерживается scikit-learn. Нет  гарантии, что параметры, переданные через этот аргумент, будут правильно взаимодействовать с scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fit(X, y, *, sample_weight=None, base_margin=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, feature_weights=None, callbacks=None)`\n",
    "\n",
    "Многократный вызов `fit()` приведет к повторному обучению модели с нуля (re-fit from scratch).\n",
    "\n",
    "Чтобы возобновить обучение с предыдущей контрольной точки, явно передайте аргумент xgb_model_gs.\n",
    "\n",
    "\n",
    "- **`X (array_like)`** - Матрица признаков.\n",
    "\n",
    "\n",
    "- **`y (array_like)`** - Labels (\"правильные ответы\").\n",
    "\n",
    "\n",
    "- **`early_stopping_rounds (int)`**\n",
    "    - Активирует раннюю остановку.\n",
    "    - Чтобы продолжить обучение, показатель валидации должен улучшаться хотя бы раз в каждом раунде `early_stopping_rounds`.\n",
    "    - Требуется хотя бы один элемент в `eval_set`.\n",
    "    - Метод возвращает модель с последней итерации (а не самой лучшей).\n",
    "    - Если в `eval_set` более одного элемента, для ранней остановки будет использоваться *последняя запись* (last entry).\n",
    "    - Если в `eval_metric` более одной метрики, для ранней остановки будет использоваться *последняя метрика* (last metric).\n",
    "    - Если произойдет ранняя остановка, модель будет иметь три дополнительных поля: `clf.best_score`, `clf.best_iteration` и `clf.best_ntree_limit`.\n",
    "\n",
    "\n",
    "- `sample_weight (array_like)` - Веса экземпляров.\n",
    "\n",
    "\n",
    "- `base_margin (array_like)` - Глобальный байес (bias) для каждого экземпляра.\n",
    "\n",
    "\n",
    "- `eval_set (list, optional)` - Список пар кортежей (X, y) для использования в качестве проверочных наборов (validation sets), для которых будут вычисляться метрики. Показатели валидации (Validation metrics) помогают отслеживать производительность (performance) модели.\n",
    "\n",
    "\n",
    "- `eval_metric (str, list of str, or callable, optional)`\n",
    "    - Если `str`, должна быть встроенная (built-in) метрика оценки для использования.\n",
    "    - Если список `list of str`, должен быть список нескольких встроенных метрик оценки для использования.\n",
    "    - Если вызываемая (`callable`), то пользовательская метрика оценки. Сигнатура вызова - `func(y_predicted, y_true)`, где `y_true` будет объектом `DMatrix`, может потребоваться вызвать метод `get_label`. Он должен возвращать пару `str, value`, где `str` - это имя для оценки, а `value` - это значение функции оценки. Вызываемая пользовательская задача (objective) всегда сводится к минимуму."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `predict(data, output_margin=False, ntree_limit=None, validate_features=True, base_margin=None)`\n",
    "\n",
    "**Эта функция не является потокобезопасной.**\n",
    "\n",
    "Для каждого объекта booster-а `predict` можно вызвать только из одного потока.\n",
    "\n",
    "Если необходимо выполнить `predict` с использованием нескольких потоков, используйте `xgb.copy()`, чтобы сделать копии объекта модели, а затем вызовите `predict()`.\n",
    "\n",
    "- **`data (numpy.array/scipy.sparse)`**\n",
    "    - Данные для прогнозирования.\n",
    "\n",
    "\n",
    "- **`validate_features (bool)`**\n",
    "    - Если это `True`, то будет произведена проверка (validate), что `feature_names` для `Booster` и `data` идентичны. В противном случае предполагается, что `feature_names` совпадают.\n",
    "\n",
    "\n",
    "- `output_margin (bool)`\n",
    "    - Выводить ли необработанное непреобразованное значение границы (margin).\n",
    "\n",
    "\n",
    "- `ntree_limit (int)`\n",
    "    - Ограничить количество деревьев в прогнозе\n",
    "    - Значение по умолчанию: `best_ntree_limit`, если он определен (т.е. он был обучен с ранней остановкой (early stopping)), в противном случае - `0` (использовать все деревья)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LevelUp_DataScience] *",
   "language": "python",
   "name": "conda-env-LevelUp_DataScience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
