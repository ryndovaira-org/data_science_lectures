{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Web scraping\n",
    "технология получения веб-данных путем извлечения их со страниц веб-ресурсов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Источники:**\n",
    "\n",
    "[Scrapy](https://scrapy.org/)\n",
    "\n",
    "[Scrapy Tutorial](https://docs.scrapy.org/en/latest/intro/tutorial.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Подготовка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ira/anaconda3/envs/LevelUp_DataScience\n",
      "\n",
      "  added / updated specs:\n",
      "    - scrapy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    itemloaders-1.0.4          |     pyhd8ed1ab_0          14 KB  conda-forge\n",
      "    jmespath-0.10.0            |     pyh9f0ad1d_0          21 KB  conda-forge\n",
      "    protego-0.1.16             |             py_0         2.6 MB  conda-forge\n",
      "    scrapy-2.4.1               |   py38h578d9bd_0         645 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  itemloaders        conda-forge/noarch::itemloaders-1.0.4-pyhd8ed1ab_0\n",
      "  jmespath           conda-forge/noarch::jmespath-0.10.0-pyh9f0ad1d_0\n",
      "  protego            conda-forge/noarch::protego-0.1.16-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi            pkgs/main::certifi-2020.12.5-py38h06a~ --> conda-forge::certifi-2020.12.5-py38h578d9bd_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2020.12.8-~ --> conda-forge::ca-certificates-2020.12.5-ha878542_0\n",
      "  openssl              pkgs/main::openssl-1.1.1i-h27cfd23_0 --> conda-forge::openssl-1.1.1i-h7f98852_0\n",
      "  scrapy             pkgs/main::scrapy-2.4.1-py38h06a4308_0 --> conda-forge::scrapy-2.4.1-py38h578d9bd_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "protego-0.1.16       | 2.6 MB    | ##################################### | 100% \n",
      "jmespath-0.10.0      | 21 KB     | ##################################### | 100% \n",
      "scrapy-2.4.1         | 645 KB    | ##################################### | 100% \n",
      "itemloaders-1.0.4    | 14 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge scrapy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scrapy\n",
    "scrapy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'scrapy_tutorial', using template directory '/home/ira/anaconda3/envs/LevelUp_DataScience/lib/python3.8/site-packages/scrapy/templates/project', created in:\n",
      "    /home/ira/LEVEL_UP/LevelUp_DataScience/2_data_engineering/lectures/scrapy_tutorial\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd scrapy_tutorial\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject scrapy_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapy 2.4.1 - no active project\n",
      "\n",
      "Unknown command: crawl\n",
      "\n",
      "Use \"scrapy\" to see available commands\n"
     ]
    }
   ],
   "source": [
    "!scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LevelUp_DataScience] *",
   "language": "python",
   "name": "conda-env-LevelUp_DataScience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
