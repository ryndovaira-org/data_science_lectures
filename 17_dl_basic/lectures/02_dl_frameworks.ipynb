{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[Caffe](https://ru.wikipedia.org/wiki/Caffe)\n",
    "\n",
    "[Caffe](https://en.wikipedia.org/wiki/Caffe_(software))\n",
    "\n",
    "[CUDA](https://ru.wikipedia.org/wiki/CUDA)\n",
    "\n",
    "[LLVM](https://ru.wikipedia.org/wiki/LLVM)\n",
    "\n",
    "[Keras](https://ru.wikipedia.org/wiki/Keras)\n",
    "\n",
    "[Keras.io documentation generator](https://github.com/keras-team/keras-io)\n",
    "\n",
    "[TensorFlow](https://ru.wikipedia.org/wiki/TensorFlow)\n",
    "\n",
    "[TensorFlow Examples](https://github.com/tensorflow/examples)\n",
    "\n",
    "[Тензорный процессор Google](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BD%D0%B7%D0%BE%D1%80%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80_Google)\n",
    "\n",
    "[Tensor Processing Unit](https://en.wikipedia.org/wiki/Tensor_Processing_Unit)\n",
    "\n",
    "[Torch](https://ru.wikipedia.org/wiki/Torch)\n",
    "\n",
    "[Torch (github)](https://github.com/torch)\n",
    "\n",
    "[Torch](https://en.wikipedia.org/wiki/Torch_(machine_learning))\n",
    "\n",
    "[MATLAB](https://en.wikipedia.org/wiki/MATLAB)\n",
    "\n",
    "[MATLAB](https://ru.wikipedia.org/wiki/MATLAB)\n",
    "\n",
    "[Mathematica](https://ru.wikipedia.org/wiki/Mathematica)\n",
    "\n",
    "[Wolfram Mathematica](https://en.wikipedia.org/wiki/Wolfram_Mathematica)\n",
    "\n",
    "[PyTorch Lightning](https://en.wikipedia.org/wiki/PyTorch_Lightning)\n",
    "\n",
    "[GNU Octave](https://ru.wikipedia.org/wiki/GNU_Octave)\n",
    "\n",
    "[GNU Octave](https://en.wikipedia.org/wiki/GNU_Octave)\n",
    "\n",
    "[PyTorch Lightning](https://pypi.org/project/pytorch-lightning/)\n",
    "\n",
    "[]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обзор библиотек/фреймворков для глубокого обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA\n",
    "\n",
    "CUDA (**Compute Unified Device Architecture**) — **программно-аппаратная архитектура параллельных вычислений**, которая позволяет существенно увеличить вычислительную производительность благодаря использованию графических процессоров фирмы **Nvidia**.\n",
    "\n",
    "CUDA SDK позволяет программистам реализовывать на специальных упрощённых диалектах языков программирования **C, C++ и Фортран** алгоритмы, выполнимые на графических и тензорных процессорах Nvidia.\n",
    "\n",
    "Функции, ускоренные при помощи CUDA, можно вызывать из различных языков, в том числе **Python**, **MATLAB** и т. п."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преимущества\n",
    "\n",
    "По сравнению с традиционным подходом к организации вычислений общего назначения посредством возможностей графических API, у архитектуры CUDA отмечают следующие преимущества в этой области:\n",
    "- Интерфейс программирования приложений CUDA (CUDA API) основан на стандартном **яыке программирования C** некоторыми ограничениями. По мнению разработчиков, это должно упростить и сгладить процесс изучения архитектуры CUDA.\n",
    "- **Разделяемая между потоками память (shared memory)** размером в 16 Кб может быть использована под организованный пользователем **с более широкой полосой пропускания**чем при выборке из обычных текстур.\n",
    "- Более **эфективные транзакции между памятью ЦП и видеопамятью**.\n",
    "- Полная **аппаратная поддержка целочисленных и побитовых операций**.\n",
    "- Поддержка компиляции кода GPU средствами открытого проекта **LLVM**. LLVM (Low Level Virtual Machine) — проект программной инфраструктуры для создания компиляторов и сопутствующих им утилит. Написан на C++, обеспечивает оптимизации на этапах компиляции, компоновки и исполнения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ограничения\n",
    "\n",
    "- Все функции, выполнимые на устройстве, **не поддерживают рекурсии** (в версии CUDA Toolkit 3.1 поддерживает указатели и рекурсию) и имеют некоторые другие ограничения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример кода (C)\n",
    "\n",
    "```c\n",
    "// System includes\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "\n",
    "// CUDA runtime\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// helper functions and utilities to work with CUDA\n",
    "#include <helper_functions.h>\n",
    "#include <helper_cuda.h>\n",
    "\n",
    "#ifndef MAX\n",
    "#define MAX(a, b) (a > b ? a : b)\n",
    "#endif\n",
    "\n",
    "__global__ void testKernel(int val) {\n",
    "  printf(\"[%d, %d]:\\t\\tValue is:%d\\n\", blockIdx.y * gridDim.x + blockIdx.x,\n",
    "         threadIdx.z * blockDim.x * blockDim.y + threadIdx.y * blockDim.x +\n",
    "             threadIdx.x,\n",
    "         val);\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "  int devID;\n",
    "  cudaDeviceProp props;\n",
    "\n",
    "  // This will pick the best possible CUDA capable device\n",
    "  devID = findCudaDevice(argc, (const char **)argv);\n",
    "\n",
    "  // Get GPU information\n",
    "  checkCudaErrors(cudaGetDevice(&devID));\n",
    "  checkCudaErrors(cudaGetDeviceProperties(&props, devID));\n",
    "  printf(\"Device %d: \\\"%s\\\" with Compute %d.%d capability\\n\", devID, props.name,\n",
    "         props.major, props.minor);\n",
    "\n",
    "  printf(\"printf() is called. Output:\\n\\n\");\n",
    "\n",
    "  // Kernel configuration, where a two-dimensional grid and\n",
    "  // three-dimensional blocks are configured.\n",
    "  dim3 dimGrid(2, 2);\n",
    "  dim3 dimBlock(2, 2, 2);\n",
    "  testKernel<<<dimGrid, dimBlock>>>(10);\n",
    "  cudaDeviceSynchronize();\n",
    "\n",
    "  return EXIT_SUCCESS;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MATLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Octave\n",
    "\n",
    "GNU Octave — свободная программная система для математических вычислений, использующая совместимый с MATLAB язык высокого уровня.\n",
    "\n",
    "Octave представляет интерактивный командный интерфейс для решения линейных и нелинейных математических задач, а также проведения других численных экспериментов. \n",
    "\n",
    "Octave — интерпретируемый язык программирования. Он похож на Си и поддерживает большинство основных функций стандартной библиотеки Си, а также основные команды и системные вызовы Unix. С другой стороны, он не поддерживает передачу аргументов по ссылке (особенность дизайна).\n",
    "\n",
    "Синтаксис языка **очень похож на MATLAB**, и грамотно написанные скрипты будут запускаться как в Octave, так и в MATLAB.\n",
    "\n",
    "<img src=\"images/gnu_octave_example_1.jpg\" width=\"700\"/>\n",
    "\n",
    "<img src=\"images/gnu_octave_example_2.png\" width=\"700\"/>\n",
    "\n",
    "<img src=\"images/gnu_octave_example_3.gif\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wolfram Mathematica\n",
    "\n",
    "Mathematica — проприетарная система компьютерной алгебры, широко используемая для научных, инженерных, математических расчётов. \n",
    "\n",
    "Разработана в 1988 году Стивеном Вольфрамом, дальнейшим развитием системы занята основанная им совместно с Теодором Греем компания Wolfram Research.\n",
    "\n",
    "**Wolfram — интерпретируемый язык функционального программирования, составляющий лингвистическую основу системы**, позволяющий расширять её возможности; более того, система Mathematica в значительной степени написана на языке Wolfram, хотя некоторые функции, особенно относящиеся к линейной алгебре, в целях оптимизации реализованы на Си.\n",
    "\n",
    "<img src=\"images/wolfram_mathematica_interface.jpg\" width=\"700\"/>\n",
    "\n",
    "<img src=\"images/wolfram_mathematica.jpg\" width=\"700\"/>\n",
    "\n",
    "Основные аналитические возможности:\n",
    "- решение систем полиномиальных и тригонометрических уравнений и неравенств, а также трансцендентных уравнений, сводящихся к ним;\n",
    "- решение рекуррентных уравнений;\n",
    "- упрощение выражений;\n",
    "- нахождение пределов;\n",
    "- интегрирование и дифференцирование функций;\n",
    "- нахождение конечных и бесконечных сумм и произведений;\n",
    "- решение дифференциальных уравнений и уравнений в частных производных;\n",
    "- преобразования Фурье и Лапласа, а также Z-преобразование;\n",
    "- преобразование функции в ряд Тейлора, операции с рядами Тейлора: сложение, умножение, композиция, получение обратной функции;\n",
    "- вейвлет-анализ.\n",
    "\n",
    "Система также осуществляет численные расчёты: \n",
    "- определяет значения функций (в том числе специальных) с произвольной точностью, \n",
    "- осуществляет полиномиальную интерполяцию функции от произвольного числа аргументов по набору известных значений, \n",
    "- рассчитывает вероятности.\n",
    "\n",
    "Теоретико-числовые возможности:\n",
    "- определение простого числа по его порядковому номеру,\n",
    "- определение количества простых чисел, не превосходящих данное; \n",
    "- дискретное преобразование Фурье; \n",
    "- разложение числа на простые множители, \n",
    "- нахождение НОД и НОК.\n",
    "\n",
    "Также в систему заложены линейно-алгебраические возможности:\n",
    "- работа с матрицами (сложение, умножение, нахождение обратной матрицы, умножение на вектор, вычисление экспоненты, взятие определителя), \n",
    "- поиск собственных значений и собственных векторов.\n",
    "\n",
    "Программы могут использовать внешние динамические библиотеки, в том числе **поддерживается интеграция с CUDA** и OpenCL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "\n",
    "TensorFlow — открытая программная библиотека для машинного обучения, разработанная компанией **Google** для решения задач построения и тренировки нейронной сети с целью автоматического **нахождения и классификации образов**, достигая качества человеческого восприятия.\n",
    "\n",
    "Основной **API** для работы с библиотекой реализован для **Python**, также существуют реализации для **R, C Sharp, C++, Haskell, Java, Go и Swift**.\n",
    "\n",
    "TensorFlow хорошо **подходит для автоматизированной аннотации изображений** в таких системах как DeepDream.\n",
    "\n",
    "Google использует систему RankBrain для **увеличения релевантности ранжировки поисковой выдачи (самообучающаяся система обрабатывающая отклики поисковой системы)** Google. RankBrain основан на TensorFlow.\n",
    "\n",
    "В мае 2016 года Google сообщила о применении для задач DL аппаратного ускорителя собственной разработки — **тензорного процессора (TPU) — специализированной интегральной схемы, адаптированной под задачи для TensorFlow**, и обеспечивающей высокую производительность в арифметике пониженной точности (например, для 8-битной архитектуры) и направленной скорее на **применение моделей, чем на их обучение**.\n",
    "\n",
    "Сообщалось, что после использования **TPU** в собственных задачах Google по обработке данных удалось добиться **на порядок лучших показателей продуктивности на ватт затраченной энергии**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример кода (Python)\n",
    "\n",
    "```python\n",
    "\"\"\"Train.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import app\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.nmt_with_attention import nmt\n",
    "from tensorflow_examples.models.nmt_with_attention import utils\n",
    "\n",
    "\n",
    "class Train(object):\n",
    "  \"\"\"Train class.\n",
    "  Attributes:\n",
    "    epochs: Number of epochs.\n",
    "    enable_function: Decorate function with tf.function.\n",
    "    encoder: Encoder.\n",
    "    decoder: Decoder.\n",
    "    inp_lang: Input language tokenizer.\n",
    "    targ_lang: Target language tokenizer.\n",
    "    batch_size: Batch size.\n",
    "    per_replica_batch_size: Batch size per replica for sync replicas. Same as\n",
    "      batch_size for non distributed training.\n",
    "    optimizer: Optimizer.\n",
    "    loss_object: Object of the loss class.\n",
    "    train_loss_metric: Mean metric to keep track of the train loss value.\n",
    "    test_loss_metric: Mean metric to keep track of the test loss value.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, epochs, enable_function, encoder, decoder, inp_lang,\n",
    "               targ_lang, batch_size, per_replica_batch_size):\n",
    "    self.epochs = epochs\n",
    "    self.enable_function = enable_function\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.inp_lang = inp_lang\n",
    "    self.targ_lang = targ_lang\n",
    "    self.batch_size = batch_size\n",
    "    self.per_replica_batch_size = per_replica_batch_size\n",
    "    self.optimizer = tf.keras.optimizers.Adam()\n",
    "    self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "    self.train_loss_metric = tf.keras.metrics.Mean(name='train_loss')\n",
    "    self.test_loss_metric = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "  def loss_function(self, real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = self.loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_) * 1. / self.batch_size\n",
    "\n",
    "  def train_step(self, inputs):\n",
    "    \"\"\"One train step.\n",
    "    Args:\n",
    "      inputs: tuple of input tensor, target tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    loss = 0\n",
    "    enc_hidden = self.encoder.initialize_hidden_state()\n",
    "\n",
    "    inp, targ = inputs\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "      enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
    "      dec_hidden = enc_hidden\n",
    "      dec_input = tf.expand_dims(\n",
    "          [self.targ_lang.word_index['<start>']] * self.per_replica_batch_size,\n",
    "          1)\n",
    "\n",
    "      for t in range(1, targ.shape[1]):\n",
    "        # passing enc_output to the decoder\n",
    "        predictions, dec_hidden, _ = self.decoder(\n",
    "            dec_input, dec_hidden, enc_output)\n",
    "        loss += self.loss_function(targ[:, t], predictions)\n",
    "        # using teacher forcing\n",
    "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = (self.encoder.trainable_variables +\n",
    "                 self.decoder.trainable_variables)\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    self.train_loss_metric(batch_loss)\n",
    "\n",
    "  def test_step(self, inputs_test):\n",
    "    \"\"\"One test step.\n",
    "    Args:\n",
    "      inputs_test: tuple of input tensor, target tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    loss = 0\n",
    "    enc_hidden = self.encoder.initialize_hidden_state()\n",
    "\n",
    "    inp_test, targ_test = inputs_test\n",
    "\n",
    "    enc_output, enc_hidden = self.encoder(inp_test, enc_hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims(\n",
    "        [self.targ_lang.word_index['<start>']] * self.per_replica_batch_size,\n",
    "        1)\n",
    "\n",
    "    for t in range(1, targ_test.shape[1]):\n",
    "      predictions, dec_hidden, _ = self.decoder(\n",
    "          dec_input, dec_hidden, enc_output)\n",
    "      loss += self.loss_function(targ_test[:, t], predictions)\n",
    "\n",
    "      prediction_id = tf.argmax(predictions, axis=1)\n",
    "      # passing the predictions back to the model as the input.\n",
    "      dec_input = tf.expand_dims(prediction_id, 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ_test.shape[1]))\n",
    "\n",
    "    self.test_loss_metric(batch_loss)\n",
    "\n",
    "  def training_loop(self, train_ds, test_ds):\n",
    "    \"\"\"Custom training and testing loop.\n",
    "    Args:\n",
    "      train_ds: Training dataset\n",
    "      test_ds: Testing dataset\n",
    "    Returns:\n",
    "      train_loss, test_loss\n",
    "    \"\"\"\n",
    "\n",
    "    if self.enable_function:\n",
    "      self.train_step = tf.function(self.train_step)\n",
    "      self.test_step = tf.function(self.test_step)\n",
    "\n",
    "    template = 'Epoch: {}, Train Loss: {}, Test Loss: {}'\n",
    "\n",
    "    for epoch in range(self.epochs):\n",
    "      self.train_loss_metric.reset_states()\n",
    "      self.test_loss_metric.reset_states()\n",
    "\n",
    "      for inp, targ in train_ds:\n",
    "        self.train_step((inp, targ))\n",
    "\n",
    "      for inp_test, targ_test in test_ds:\n",
    "        self.test_step((inp_test, targ_test))\n",
    "\n",
    "      print (template.format(epoch,\n",
    "                             self.train_loss_metric.result().numpy(),\n",
    "                             self.test_loss_metric.result().numpy()))\n",
    "\n",
    "    return (self.train_loss_metric.result().numpy(),\n",
    "            self.test_loss_metric.result().numpy())\n",
    "\n",
    "\n",
    "def run_main(argv):\n",
    "  del argv\n",
    "  kwargs = utils.flags_dict()\n",
    "  main(**kwargs)\n",
    "\n",
    "\n",
    "def main(epochs, enable_function, buffer_size, batch_size, download_path,\n",
    "         num_examples=70000, embedding_dim=256, enc_units=1024, dec_units=1024):\n",
    "  file_path = utils.download(download_path)\n",
    "  train_ds, test_ds, inp_lang, targ_lang = utils.create_dataset(\n",
    "      file_path, num_examples, buffer_size, batch_size)\n",
    "  vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "  vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "\n",
    "  encoder = nmt.Encoder(vocab_inp_size, embedding_dim, enc_units, batch_size)\n",
    "  decoder = nmt.Decoder(vocab_tar_size, embedding_dim, dec_units)\n",
    "\n",
    "  train_obj = Train(epochs, enable_function, encoder, decoder,\n",
    "                    inp_lang, targ_lang, batch_size, batch_size)\n",
    "  print ('Training ...')\n",
    "  return train_obj.training_loop(train_ds, test_ds)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  utils.nmt_flags()\n",
    "  app.run(run_main)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тензорный процессор Google\n",
    "\n",
    "Тензорный процессор Google (Google Tensor Processing Unit, Google TPU) — тензорный процессор, относящийся к классу **нейронных процессоров**, являющийся специализированной интегральной схемой, разработанной корпорацией Google и предназначенной **для использования с библиотекой машинного обучения TensorFlow**.\n",
    "\n",
    "<img src=\"images/tpu_3_0.jpg\" width=\"700\"/>\n",
    "\n",
    "По сравнению с GPU, рассчитан на более **высокий объём вычислений с пониженной точностью** (например, всего 8-разрядную точность) при более **высокой производительности на ватт** и **отсутствии модуля для растризации и текстурных блоков**.\n",
    "\n",
    "Различные типы процессоров подходят для разных типов моделей машинного обучения, **TPU хорошо подходят для CNN**, в то время как **GPU имеют преимущества для некоторых полносвязных нейронных сетей**, а **CPU могут иметь преимущества для RNN**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример кода (Python & TPU)\n",
    "\n",
    "```python\n",
    "\"\"\"Example for using Keras Application models using TPU Strategy.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import flags\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.contrib import cluster_resolver as contrib_cluster_resolver\n",
    "from tensorflow.contrib import distribute as contrib_distribute\n",
    "\n",
    "\n",
    "# Define a dictionary that maps model names to their model classes inside Keras\n",
    "MODELS = {\n",
    "    \"vgg16\": tf.keras.applications.VGG16,\n",
    "    \"vgg19\": tf.keras.applications.VGG19,\n",
    "    \"inceptionv3\": tf.keras.applications.InceptionV3,\n",
    "    \"xception\": tf.keras.applications.Xception,\n",
    "    \"resnet50\": tf.keras.applications.ResNet50,\n",
    "    \"inceptionresnetv2\": tf.keras.applications.InceptionResNetV2,\n",
    "    \"mobilenet\": tf.keras.applications.MobileNet,\n",
    "    \"densenet121\": tf.keras.applications.DenseNet121,\n",
    "    \"densenet169\": tf.keras.applications.DenseNet169,\n",
    "    \"densenet201\": tf.keras.applications.DenseNet201,\n",
    "    \"nasnetlarge\": tf.keras.applications.NASNetLarge,\n",
    "    \"nasnetmobile\": tf.keras.applications.NASNetMobile,\n",
    "}\n",
    "\n",
    "flags.DEFINE_enum(\n",
    "    \"model\",\n",
    "    None,\n",
    "    list(MODELS.keys()),\n",
    "    \"Name of the model to be run\",\n",
    "    case_sensitive=False)\n",
    "flags.DEFINE_string(\"tpu\", None, \"Name of the TPU to use\")\n",
    "flags.DEFINE_integer(\"batch_size\", 128, \"Batch size to be used for model\")\n",
    "flags.DEFINE_integer(\"epochs\", 10, \"Number of training epochs\")\n",
    "flags.DEFINE_bool(\"use_synthetic_data\", False,\n",
    "                  \"Use synthetic data instead of Cifar; used for testing\")\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "class Cifar10Dataset(object):\n",
    "  \"\"\"CIFAR10 dataset, including train and test set.\n",
    "  Each sample consists of a 32x32 color image, and label is from 10 classes.\n",
    "  Note: Some models such as Xception require larger images than 32x32 so one\n",
    "  needs to write a tf.data.dataset for Imagenet or use synthetic data.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, batch_size):\n",
    "    \"\"\"Initializes train/test datasets.\n",
    "    Args:\n",
    "      batch_size: int, the number of batch size.\n",
    "    \"\"\"\n",
    "    self.input_shape = (32, 32, 3)\n",
    "    self.num_classes = 10\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    self.num_train_images = len(x_train)\n",
    "    self.num_test_images = len(x_test)\n",
    "\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    y_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, self.num_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "    self.train_dataset = (tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "                          .repeat()\n",
    "                          .shuffle(2000)\n",
    "                          .batch(batch_size, drop_remainder=True))\n",
    "    self.test_dataset = (tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "                         .shuffle(2000)\n",
    "                         .batch(batch_size, drop_remainder=True))\n",
    "\n",
    "\n",
    "class SyntheticDataset(object):\n",
    "  \"\"\"Synthetic dataset, including train and test set.\n",
    "  Each sample consists of a 100x100 color image, and label is from 10 classes.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, batch_size):\n",
    "    \"\"\"Initializes train/test datasets.\n",
    "    Args:\n",
    "      batch_size: int, the number of batch size.\n",
    "    \"\"\"\n",
    "    image_size = 75\n",
    "    self.input_shape = (image_size, image_size, 3)\n",
    "    self.num_train_images = 2 * batch_size  # Run 2 steps\n",
    "    self.num_test_images = batch_size  # Run 1 step\n",
    "    self.num_classes = 10\n",
    "\n",
    "    x_train = np.random.randn(\n",
    "        self.num_train_images, image_size, image_size, 3).astype(np.float32)\n",
    "    y_train = np.random.randint(self.num_classes, size=self.num_train_images,\n",
    "                                dtype=np.int32)\n",
    "    y_train = y_train.reshape((self.num_train_images, 1))\n",
    "\n",
    "    x_test = np.random.randn(\n",
    "        self.num_test_images, image_size, image_size, 3).astype(np.float32)\n",
    "    y_test = np.random.randint(self.num_classes, size=self.num_test_images,\n",
    "                               dtype=np.int32)\n",
    "    y_test = y_test.reshape((self.num_test_images, 1))\n",
    "\n",
    "    y_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, self.num_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "    self.train_dataset = (tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "                          .repeat()\n",
    "                          .shuffle(2000)\n",
    "                          .batch(batch_size, drop_remainder=True))\n",
    "    self.test_dataset = (tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "                         .shuffle(2000)\n",
    "                         .batch(batch_size, drop_remainder=True))\n",
    "\n",
    "\n",
    "def run():\n",
    "  \"\"\"Run the model training and return evaluation output.\"\"\"\n",
    "  resolver = contrib_cluster_resolver.TPUClusterResolver(tpu=FLAGS.tpu)\n",
    "  contrib_distribute.initialize_tpu_system(resolver)\n",
    "  strategy = contrib_distribute.TPUStrategy(resolver)\n",
    "\n",
    "  model_cls = MODELS[FLAGS.model]\n",
    "  if FLAGS.use_synthetic_data:\n",
    "    data = SyntheticDataset(FLAGS.batch_size)\n",
    "  else:\n",
    "    data = Cifar10Dataset(FLAGS.batch_size)\n",
    "\n",
    "  with strategy.scope():\n",
    "    model = model_cls(weights=None, input_shape=data.input_shape,\n",
    "                      classes=data.num_classes)\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(\n",
    "        data.train_dataset,\n",
    "        epochs=FLAGS.epochs,\n",
    "        steps_per_epoch=data.num_train_images // FLAGS.batch_size,\n",
    "        validation_data=data.test_dataset,\n",
    "        validation_steps=data.num_test_images // FLAGS.batch_size)\n",
    "\n",
    "    return history.history\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "  del argv\n",
    "  run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.app.run(main)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "Keras — открытая библиотека, **написанная на языке Python** и обеспечивающая взаимодействие с искусственными нейронными сетями.\n",
    "\n",
    "Основной автор и ведущий разработчик — инженер **Google** Франсуа Шолле (фр. François Chollet).\n",
    "\n",
    "**Keras действует как интерфейс для библиотеки TensorFlow.**\n",
    "\n",
    "Начиная с версии 2.4 **поддерживается только TensorFlow**.\n",
    "\n",
    "Модели, созданные в Keras, могут быть развёрнуты не только на серверных узлах, но и на смартфонах (под управлением iOS и Android) и в браузере (TF.js)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример кода (Python)\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Title: Convolutional autoencoder for image denoising\n",
    "Author: [Santiago L. Valdarrama](https://twitter.com/svpino)\n",
    "Date created: 2021/03/01\n",
    "Last modified: 2021/03/01\n",
    "Description: How to train a deep convolutional autoencoder for image denoising.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Introduction\n",
    "\n",
    "This example demonstrates how to implement a deep convolutional autoencoder\n",
    "for image denoising, mapping noisy digits images from the MNIST dataset to\n",
    "clean digits images. This implementation is based on an original blog post\n",
    "titled [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "by [François Chollet](https://twitter.com/fchollet).\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Setup\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def preprocess(array):\n",
    "    \"\"\"\n",
    "    Normalizes the supplied array and reshapes it into the appropriate format.\n",
    "    \"\"\"\n",
    "\n",
    "    array = array.astype(\"float32\") / 255.0\n",
    "    array = np.reshape(array, (len(array), 28, 28, 1))\n",
    "    return array\n",
    "\n",
    "\n",
    "def noise(array):\n",
    "    \"\"\"\n",
    "    Adds random noise to each image in the supplied array.\n",
    "    \"\"\"\n",
    "\n",
    "    noise_factor = 0.4\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "\n",
    "    return np.clip(noisy_array, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def display(array1, array2):\n",
    "    \"\"\"\n",
    "    Displays ten random images from each one of the supplied arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    n = 10\n",
    "\n",
    "    indices = np.random.randint(len(array1), size=n)\n",
    "    images1 = array1[indices, :]\n",
    "    images2 = array2[indices, :]\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(image1.reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(image2.reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Prepare the data\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Since we only need images from the dataset to encode and decode, we won't use the labels. \"\"\"\n",
    "(train_data, _), (test_data, _) = mnist.load_data()\n",
    "\n",
    "\"\"\" Normalize and reshape the data \"\"\"\n",
    "train_data = preprocess(train_data)\n",
    "test_data = preprocess(test_data)\n",
    "\n",
    "\"\"\" Create a copy of the data with added noise \"\"\"\n",
    "noisy_train_data = noise(train_data)\n",
    "noisy_test_data = noise(test_data)\n",
    "\n",
    "\"\"\" Display the train data and a version of it with added noise \"\"\"\n",
    "display(train_data, noisy_train_data)\n",
    "\n",
    "\"\"\"\n",
    "Build the autoencoder\n",
    "\n",
    "We are going to use the Functional API to build our convolutional autoencoder.\n",
    "\"\"\"\n",
    "\n",
    "input = layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "\"\"\" Encoder \"\"\"\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "\"\"\" Decoder \"\"\"\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "\"\"\" Autoencoder \"\"\"\n",
    "autoencoder = Model(input, x)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "autoencoder.summary()\n",
    "\n",
    "\"\"\"\n",
    "Now we can train our autoencoder using `train_data` as both our input data\n",
    "and target. Notice we are setting up the validation data using the same\n",
    "format.\n",
    "\"\"\"\n",
    "\n",
    "autoencoder.fit(\n",
    "    x=train_data,\n",
    "    y=train_data,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(test_data, test_data),\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Let's predict on our test dataset and display the original image together with\n",
    "the prediction from our autoencoder.\n",
    "\n",
    "Notice how the predictions are pretty close to the original images, although\n",
    "not quite the same.\n",
    "\"\"\"\n",
    "\n",
    "predictions = autoencoder.predict(test_data)\n",
    "display(test_data, predictions)\n",
    "\n",
    "\"\"\"\n",
    "Now that we know that our autoencoder works, let's retrain it using the noisy\n",
    "data as our input and the clean data as our target. We want our autoencoder to\n",
    "learn how to denoise the images.\n",
    "\"\"\"\n",
    "\n",
    "autoencoder.fit(\n",
    "    x=noisy_train_data,\n",
    "    y=train_data,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(noisy_test_data, test_data),\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Let's now predict on the noisy data and display the results of our autoencoder.\n",
    "\n",
    "Notice how the autoencoder does an amazing job at removing the noise from the\n",
    "input images.\n",
    "\"\"\"\n",
    "\n",
    "predictions = autoencoder.predict(noisy_test_data)\n",
    "display(noisy_test_data, predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch\n",
    "\n",
    "Torch — библиотека для языка программирования **Lua** с открытым исходным кодом, предоставляет большое количество алгоритмов для глубинного обучения и научных расчётов.\n",
    "\n",
    "Ядро написано на Си, прикладная часть выполняется на LuaJIT, поддерживается распараллеливание вычислений средствами CUDA и OpenMP.\n",
    "\n",
    "**Стиль работы с массивами схож с Matlab и Octave, в связи с чем иногда определяется как \"Matlab-подобное окружение для машинного обучения\".**\n",
    "\n",
    "По состоянию на 2018 год **Torch больше не находится в активной разработке**. Однако по состоянию на август 2022 года **PyTorch, основанный на библиотеке Torch, активно развивается**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример кода (Lua)\n",
    "\n",
    "```lua\n",
    "require 'torch'   -- torch\n",
    "require 'image'   -- for image transforms\n",
    "require 'nn'      -- provides all sorts of trainable modules/layers\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "-- parse command line arguments\n",
    "if not opt then\n",
    "   print '==> processing options'\n",
    "   cmd = torch.CmdLine()\n",
    "   cmd:text()\n",
    "   cmd:text('SVHN Model Definition')\n",
    "   cmd:text()\n",
    "   cmd:text('Options:')\n",
    "   cmd:option('-model', 'convnet', 'type of model to construct: linear | mlp | convnet')\n",
    "   cmd:option('-visualize', true, 'visualize input data and weights during training')\n",
    "   cmd:text()\n",
    "   opt = cmd:parse(arg or {})\n",
    "end\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "print '==> define parameters'\n",
    "\n",
    "-- 10-class problem\n",
    "noutputs = 10\n",
    "\n",
    "-- input dimensions\n",
    "nfeats = 3\n",
    "width = 32\n",
    "height = 32\n",
    "ninputs = nfeats*width*height\n",
    "\n",
    "-- number of hidden units (for MLP only):\n",
    "nhiddens = ninputs / 2\n",
    "\n",
    "-- hidden units, filter sizes (for ConvNet only):\n",
    "nstates = {64,64,128}\n",
    "filtsize = 5\n",
    "poolsize = 2\n",
    "normkernel = image.gaussian1D(7)\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "print '==> construct model'\n",
    "\n",
    "if opt.model == 'linear' then\n",
    "\n",
    "   -- Simple linear model\n",
    "   model = nn.Sequential()\n",
    "   model:add(nn.Reshape(ninputs))\n",
    "   model:add(nn.Linear(ninputs,noutputs))\n",
    "\n",
    "elseif opt.model == 'mlp' then\n",
    "\n",
    "   -- Simple 2-layer neural network, with tanh hidden units\n",
    "   model = nn.Sequential()\n",
    "   model:add(nn.Reshape(ninputs))\n",
    "   model:add(nn.Linear(ninputs,nhiddens))\n",
    "   model:add(nn.Tanh())\n",
    "   model:add(nn.Linear(nhiddens,noutputs))\n",
    "\n",
    "elseif opt.model == 'convnet' then\n",
    "\n",
    "   if opt.type == 'cuda' then\n",
    "      -- a typical modern convolution network (conv+relu+pool)\n",
    "      model = nn.Sequential()\n",
    "\n",
    "      -- stage 1 : filter bank -> squashing -> L2 pooling -> normalization\n",
    "      model:add(nn.SpatialConvolutionMM(nfeats, nstates[1], filtsize, filtsize))\n",
    "      model:add(nn.ReLU())\n",
    "      model:add(nn.SpatialMaxPooling(poolsize,poolsize,poolsize,poolsize))\n",
    "\n",
    "      -- stage 2 : filter bank -> squashing -> L2 pooling -> normalization\n",
    "      model:add(nn.SpatialConvolutionMM(nstates[1], nstates[2], filtsize, filtsize))\n",
    "      model:add(nn.ReLU())\n",
    "      model:add(nn.SpatialMaxPooling(poolsize,poolsize,poolsize,poolsize))\n",
    "\n",
    "      -- stage 3 : standard 2-layer neural network\n",
    "      model:add(nn.View(nstates[2]*filtsize*filtsize))\n",
    "      model:add(nn.Dropout(0.5))\n",
    "      model:add(nn.Linear(nstates[2]*filtsize*filtsize, nstates[3]))\n",
    "      model:add(nn.ReLU())\n",
    "      model:add(nn.Linear(nstates[3], noutputs))\n",
    "\n",
    "   else\n",
    "      -- a typical convolutional network, with locally-normalized hidden\n",
    "      -- units, and L2-pooling\n",
    "\n",
    "      -- Note: the architecture of this convnet is loosely based on Pierre Sermanet's\n",
    "      -- work on this dataset (http://arxiv.org/abs/1204.3968). In particular\n",
    "      -- the use of LP-pooling (with P=2) has a very positive impact on\n",
    "      -- generalization. Normalization is not done exactly as proposed in\n",
    "      -- the paper, and low-level (first layer) features are not fed to\n",
    "      -- the classifier.\n",
    "\n",
    "      model = nn.Sequential()\n",
    "\n",
    "      -- stage 1 : filter bank -> squashing -> L2 pooling -> normalization\n",
    "      model:add(nn.SpatialConvolutionMM(nfeats, nstates[1], filtsize, filtsize))\n",
    "      model:add(nn.Tanh())\n",
    "      model:add(nn.SpatialLPPooling(nstates[1],2,poolsize,poolsize,poolsize,poolsize))\n",
    "      model:add(nn.SpatialSubtractiveNormalization(nstates[1], normkernel))\n",
    "\n",
    "      -- stage 2 : filter bank -> squashing -> L2 pooling -> normalization\n",
    "      model:add(nn.SpatialConvolutionMM(nstates[1], nstates[2], filtsize, filtsize))\n",
    "      model:add(nn.Tanh())\n",
    "      model:add(nn.SpatialLPPooling(nstates[2],2,poolsize,poolsize,poolsize,poolsize))\n",
    "      model:add(nn.SpatialSubtractiveNormalization(nstates[2], normkernel))\n",
    "\n",
    "      -- stage 3 : standard 2-layer neural network\n",
    "      model:add(nn.Reshape(nstates[2]*filtsize*filtsize))\n",
    "      model:add(nn.Linear(nstates[2]*filtsize*filtsize, nstates[3]))\n",
    "      model:add(nn.Tanh())\n",
    "      model:add(nn.Linear(nstates[3], noutputs))\n",
    "   end\n",
    "else\n",
    "\n",
    "   error('unknown -model')\n",
    "\n",
    "end\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "print '==> here is the model:'\n",
    "print(model)\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "-- Visualization is quite easy, using itorch.image().\n",
    "\n",
    "if opt.visualize then\n",
    "   if opt.model == 'convnet' then\n",
    "      if itorch then\n",
    "\t print '==> visualizing ConvNet filters'\n",
    "\t print('Layer 1 filters:')\n",
    "\t itorch.image(model:get(1).weight)\n",
    "\t print('Layer 2 filters:')\n",
    "\t itorch.image(model:get(5).weight)\n",
    "      else\n",
    "\t print '==> To visualize filters, start the script in itorch notebook'\n",
    "      end\n",
    "   end\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример кода (Lua & CUDA)\n",
    "\n",
    "```lua\n",
    "require 'cutorch'\n",
    "\n",
    "t1 = torch.randn(1000):cuda()\n",
    "t2 = torch.randn(1000):cuda()\n",
    "\n",
    "t1:add(t2)\n",
    "\n",
    "t1_f = t1:float()\n",
    "\n",
    "print{t1}\n",
    "print{t1_f}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "<img src=\"images/pytorch_logo.png\"/>\n",
    "\n",
    "PyTorch — это платформа машинного обучения **с открытым исходным кодом, основанная на библиотеке Torch**, используемая для таких приложений, как компьютерное зрение и обработка естественного языка, в первую очередь разработанная **Meta AI**. \n",
    "\n",
    "Хотя интерфейс Python более совершенен и находится в центре внимания разработки, PyTorch также имеет интерфейс C++.\n",
    "\n",
    "Также вокруг этого фреймворка выстроена экосистема, состоящая из различных библиотек, разрабатываемых сторонними командами: **PyTorch Lightning** и **Fast.ai**, упрощающие процесс обучения моделей, **Pyro**, модуль для вероятностного программирования, от Uber, **Flair**, для обработки естественного языка и **Catalyst**, для обучения DL и RL моделей.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\") # This executes all calculations on the CPU\n",
    "# device = torch.device(\"cuda:0\") # This executes all calculations on the GPU\n",
    "\n",
    "# Creation of a tensor and filling of a tensor with random numbers\n",
    "a = torch.randn(2, 3, device=device, dtype=dtype)\n",
    "print(a) # Output of tensor A\n",
    "# Output: tensor([[-1.1884,  0.8498, -1.7129],\n",
    "#                  [-0.8816,  0.1944,  0.5847]])\n",
    "\n",
    "# Creation of a tensor and filling of a tensor with random numbers\n",
    "b = torch.randn(2, 3, device=device, dtype=dtype)\n",
    "print(b) # Output of tensor B\n",
    "# Output: tensor([[ 0.7178, -0.8453, -1.3403],\n",
    "#                  [ 1.3262,  1.1512, -1.7070]])\n",
    "\n",
    "print(a*b) # Output of a multiplication of the two tensors\n",
    "# Output: tensor([[-0.8530, -0.7183,  2.58],\n",
    "#                  [-1.1692,  0.2238, -0.9981]])\n",
    "\n",
    "print(a.sum()) # Output of the sum of all elements in tensor A\n",
    "# Output: tensor(-2.1540)\n",
    "\n",
    "print(a[1,2]) # Output of the element in the third column of the second row\n",
    "# Output: tensor(0.5847)\n",
    "\n",
    "print(a.min()) # Output of the minimum value in tensor A\n",
    "# Output: tensor(-1.7129)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caffe\n",
    "\n",
    "Caffe (**Convolution Architecture For Feature Extraction** = Свёрточная архитектура для извлечения признаков) — среда для глубокого обучения, разработанная Яньцинем Цзя (Yangqing Jia) в процессе подготовки своей диссертации в университете Беркли. \n",
    "\n",
    "Caffe является открытым программным обеспечением, распространяемым под лицензией BSD license. \n",
    "\n",
    "Написано на языке C++, и поддерживает **интерфейс на языке Python**.\n",
    "\n",
    "Caffe поддерживает много типов машинного обучения, нацеленных в первую очередь на решение задач **классификации** и **сегментации изображений**. \n",
    "\n",
    "Для ускорения обучения применяется система графических процессоров (GPU), поддерживаемая архитектурой **CUDA** и иcпользующих библиотеку CuDNN от фирмы **Nvidia**.\n",
    "\n",
    "**В мае 2018 команды Caffe2 и PyTorch объединились. С тех пор код Caffe2 перенесён в репозиторий PyTorch и является частью последнего.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PyTorch Lightning\n",
    "\n",
    "<img src=\"images/pytorch_lightning_logo.png\"/>\n",
    "\n",
    "PyTorch Lightning — это библиотека Python с открытым исходным кодом, которая предоставляет **высокоуровневый интерфейс для PyTorch**, популярной среды глубокого обучения.\n",
    "\n",
    "Он предназначен для создания **масштабируемых моделей глубокого обучения**, которые могут легко работать на распределенном оборудовании, сохраняя при этом **аппаратно-независимые модели**.\n",
    "\n",
    "Lightning применяет следующую структуру к вашему коду, что делает его повторно используемым и доступным:\n",
    "- Исследовательский код (LightningModule). \n",
    "- Инженерный код (вы удаляете, а обрабатывается Трейнером). \n",
    "- Несущественный исследовательский код (логирование и т. д., это относится к обратным вызовам).\n",
    "- Данные (используйте PyTorch DataLoaders или организуйте их в LightningDataModule).\n",
    "\n",
    "**Как только вы это сделаете, вы сможете тренироваться на нескольких GPU, TPU, CPU, IPU, HPU и даже с 16-битной точностью без изменения кода!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data-science-course-original] *",
   "language": "python",
   "name": "conda-env-data-science-course-original-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
