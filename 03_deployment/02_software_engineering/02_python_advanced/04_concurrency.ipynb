{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Параллелизм/Конкурентность (Concurrency)\n",
    "\n",
    "В русскоязычной литературе нередко путаются термины **\"параллелизм\"** и **\"конкурентность\"**.\n",
    "\n",
    "Оба термина означают одновременность процессов, но **\"параллелизм\"** — **на физическом уровне** (параллельное исполнение нескольких процессов, нацеленное только на повышение скорости исполнения за счёт использования соответствующей аппаратной поддержки), а **\"конкурентность\"** — **на логическом** (парадигма проектирования систем, идентифицирующая процессы как независимые, что в том числе позволяет их исполнять физически параллельно, но в первую очередь нацелено на упрощение написания многопоточных программ и повышение их устойчивости)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Источники:**\n",
    "\n",
    "[Concurrency in Python](https://stackabuse.com/concurrency-in-python/)\n",
    "\n",
    "[Параллелизм (информатика)](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D0%B8%D0%B7%D0%BC_(%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0))\n",
    "\n",
    "[Concurrent computing](https://en.wikipedia.org/wiki/Concurrent_computing)\n",
    "\n",
    "[Параллельные вычисления](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F)\n",
    "\n",
    "[Concurrency (computer science)](https://en.wikipedia.org/wiki/Concurrency_(computer_science))\n",
    "\n",
    "[Speed Up Your Python Program With Concurrency](https://realpython.com/python-concurrency/)\n",
    "\n",
    "[Multi-core processor](https://en.wikipedia.org/wiki/Multi-core_processor)\n",
    "\n",
    "[Чрезвычайная параллельность](https://ru.wikipedia.org/wiki/%D0%A7%D1%80%D0%B5%D0%B7%D0%B2%D1%8B%D1%87%D0%B0%D0%B9%D0%BD%D0%B0%D1%8F_%D0%BF%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C)\n",
    "\n",
    "[Закон Амдала](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%BA%D0%BE%D0%BD_%D0%90%D0%BC%D0%B4%D0%B0%D0%BB%D0%B0)\n",
    "\n",
    "[Amdahl’s law illustrated](https://www.javacodegeeks.com/2013/02/amdahls-law-illustrated.html)\n",
    "\n",
    "[Multi vs Multi](https://medium.com/@tarunjain07/multi-vs-multi-cb9b0ec382ad)\n",
    "\n",
    "[Python Multithreading vs Multiprocessing](https://thinkinfi.com/python-multithreading-vs-multiprocessing/)\n",
    "\n",
    "[Многопоточность](https://ru.wikipedia.org/wiki/%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D0%BF%D0%BE%D1%82%D0%BE%D1%87%D0%BD%D0%BE%D1%81%D1%82%D1%8C)\n",
    "\n",
    "[Multithreading (computer architecture)](https://en.wikipedia.org/wiki/Multithreading_(computer_architecture))\n",
    "\n",
    "[Multiprocessing](https://en.wikipedia.org/wiki/Multiprocessing)\n",
    "\n",
    "[Process (computing)](https://en.wikipedia.org/wiki/Process_(computing))\n",
    "\n",
    "[Процесс (информатика)](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81_(%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0))\n",
    "\n",
    "[Context switch](https://en.wikipedia.org/wiki/Context_switch)\n",
    "\n",
    "[Переключение контекста](https://ru.wikipedia.org/wiki/%D0%9F%D0%B5%D1%80%D0%B5%D0%BA%D0%BB%D1%8E%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BA%D0%BE%D0%BD%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0)\n",
    "\n",
    "[Поток выполнения](https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D1%82%D0%BE%D0%BA_%D0%B2%D1%8B%D0%BF%D0%BE%D0%BB%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F)\n",
    "\n",
    "[Thread (computing)](https://en.wikipedia.org/wiki/Thread_(computing))\n",
    "\n",
    "[Thread-safety](https://ru.wikipedia.org/wiki/Thread-safety)\n",
    "\n",
    "[Global interpreter lock](https://en.wikipedia.org/wiki/Global_interpreter_lock)\n",
    "\n",
    "[Глобальная блокировка интерпретатора](https://ru.wikipedia.org/wiki/%D0%93%D0%BB%D0%BE%D0%B1%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%B8%D0%BD%D1%82%D0%B5%D1%80%D0%BF%D1%80%D0%B5%D1%82%D0%B0%D1%82%D0%BE%D1%80%D0%B0)\n",
    "\n",
    "[Задача об обедающих философах](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BE%D0%B1_%D0%BE%D0%B1%D0%B5%D0%B4%D0%B0%D1%8E%D1%89%D0%B8%D1%85_%D1%84%D0%B8%D0%BB%D0%BE%D1%81%D0%BE%D1%84%D0%B0%D1%85)\n",
    "\n",
    "[Starvation (computer science)](https://en.wikipedia.org/wiki/Starvation_(computer_science))\n",
    "\n",
    "[Deadlock](https://en.wikipedia.org/wiki/Deadlock)\n",
    "\n",
    "[Time-sharing](https://en.wikipedia.org/wiki/Time-sharing)\n",
    "\n",
    "[Разделение времени](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%B8)\n",
    "\n",
    "[Gustafson's law](https://en.wikipedia.org/wiki/Gustafson%27s_law)\n",
    "\n",
    "[Закон Густавсона — Барсиса](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%BA%D0%BE%D0%BD_%D0%93%D1%83%D1%81%D1%82%D0%B0%D0%B2%D1%81%D0%BE%D0%BD%D0%B0_%E2%80%94_%D0%91%D0%B0%D1%80%D1%81%D0%B8%D1%81%D0%B0)\n",
    "\n",
    "[Throughput](https://en.wikipedia.org/wiki/Throughput)\n",
    "\n",
    "[Memory management](https://en.wikipedia.org/wiki/Memory_management#ALLOCATION)\n",
    "\n",
    "[Latency (engineering)](https://en.wikipedia.org/wiki/Latency_(engineering))\n",
    "\n",
    "[Channel (programming)](https://en.wikipedia.org/wiki/Channel_(programming))\n",
    "\n",
    "[Канал (программирование)](https://ru.wikipedia.org/wiki/%D0%9A%D0%B0%D0%BD%D0%B0%D0%BB_(%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5))\n",
    "\n",
    "[Coroutine](https://en.wikipedia.org/wiki/Coroutine)\n",
    "\n",
    "[Сопрограмма](https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0)\n",
    "\n",
    "[Fiber (computer science)](https://en.wikipedia.org/wiki/Fiber_(computer_science))\n",
    "\n",
    "[Futures and promises](https://en.wikipedia.org/wiki/Futures_and_promises)\n",
    "\n",
    "[Futures and promises (ru)](https://ru.wikipedia.org/wiki/Futures_and_promises)\n",
    "\n",
    "[Асинхронность](https://ru.wikipedia.org/wiki/%D0%90%D1%81%D0%B8%D0%BD%D1%85%D1%80%D0%BE%D0%BD%D0%BD%D0%BE%D1%81%D1%82%D1%8C)\n",
    "\n",
    "[Асинхронный ввод-вывод](https://ru.wikipedia.org/wiki/%D0%90%D1%81%D0%B8%D0%BD%D1%85%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B2%D0%B2%D0%BE%D0%B4-%D0%B2%D1%8B%D0%B2%D0%BE%D0%B4)\n",
    "\n",
    "[Asynchrony (computer programming)](https://en.wikipedia.org/wiki/Asynchrony_(computer_programming))\n",
    "\n",
    "[Async/await](https://en.wikipedia.org/wiki/Async/await)\n",
    "\n",
    "[Pool (computer science)](https://en.wikipedia.org/wiki/Pool_(computer_science))\n",
    "\n",
    "[Object pool pattern](https://en.wikipedia.org/wiki/Object_pool_pattern)\n",
    "\n",
    "[Объектный пул](https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BD%D1%8B%D0%B9_%D0%BF%D1%83%D0%BB)\n",
    "\n",
    "[Thread pool](https://en.wikipedia.org/wiki/Thread_pool)\n",
    "\n",
    "[Многопоточность в Python](https://dev-gang.ru/article/mnogopotocznost-v-python-t2bkyunvku/)\n",
    "\n",
    "[Модуль multiprocessing на примерах](http://python-3.ru/page/multiprocessing)\n",
    "\n",
    "[Многопроцессорная обработка в Python](http://python-3.ru/page/multiprocessing)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что такое конкурентность?\n",
    "\n",
    "В информатике **конкурентность** - это способность различных частей программы, алгоритма или задачи выполняться не по порядку или в частичном порядке, *не влияя на конечный результат*.\n",
    "\n",
    "Это позволяет выполнять **параллельное** выполнение **конкурентных** модулей, что может значительно повысить общую скорость выполнения в *многопроцессорных* и *многоядерных* системах.\n",
    "\n",
    "Другими словами **конкурентность** относится к разложению программы, алгоритма или проблемы на независимые от порядка или частично упорядоченные компоненты или единицы вычислений.\n",
    "\n",
    "Существуют различные способы реализации **конкурентных** вычислений. \n",
    "\n",
    "Например, каждый вычислительный процесс может быть реализован в виде **процесса** операционной системы, либо же вычислительные **процессы** могут представлять собой набор **потоков** выполнения внутри одного процесса ОС.\n",
    "\n",
    "**Конкурентные** программы могут физически исполняться либо *последовательно на единственном процессоре* — перемежая по очереди шаги выполнения каждого вычислительного процесса, либо *параллельно — выделяя каждому вычислительному процессу один или несколько процессоров* (находящихся рядом или распределённых в компьютерную сеть).\n",
    "\n",
    "### Проблемы\n",
    "\n",
    "Классическая [задача об обедающих философах](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BE%D0%B1_%D0%BE%D0%B1%D0%B5%D0%B4%D0%B0%D1%8E%D1%89%D0%B8%D1%85_%D1%84%D0%B8%D0%BB%D0%BE%D1%81%D0%BE%D1%84%D0%B0%D1%85).\n",
    "\n",
    "\n",
    "Поскольку вычисления в **конкурентных** системах взаимодействуют друг с другом, число возможных путей выполнения может быть чрезвычайно велико, и результирующий итог может стать *недетерминированным (неопределенным)*\n",
    "\n",
    "**Конкурентное** использование общих ресурсов может стать одним из источников недетерминированности, приводящей к таким проблемам, как *взаимная блокировка (deadlock)* или *фатальный недостаток ресурсов (resource starvation)*.\n",
    "\n",
    "Построение **конкурентных** систем требует поиска надёжных методов координации выполняемых процессов, обмена данными, распределения памяти (memory allocation) и планирования для минимизации времени отклика (latency) и увеличения пропускной способности (throughput).\n",
    "\n",
    "**Конкурентные** вычисления — способ организации компьютерных вычислений, при котором программы разрабатываются как набор взаимодействующих вычислительных процессов, работающих параллельно (одновременно).\n",
    "\n",
    "Основная сложность при проектировании **конкурентных** программ — обеспечить правильную последовательность взаимодействий между различными вычислительными процессами, а также координацию ресурсов, разделяемых между процессами.\n",
    "\n",
    "### Преимущества\n",
    "\n",
    "- Повышенная производительность программы - параллельное выполнение **конкурентной** программы позволяет количеству задач, выполненных за заданное время, увеличиваться пропорционально количеству процессоров в соответствии с законом [Густафсона](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%BA%D0%BE%D0%BD_%D0%93%D1%83%D1%81%D1%82%D0%B0%D0%B2%D1%81%D0%BE%D0%BD%D0%B0_%E2%80%94_%D0%91%D0%B0%D1%80%D1%81%D0%B8%D1%81%D0%B0).\n",
    "- Высокая скорость реакции на ввод/вывод - программы с интенсивным вводом/выводом в основном ждут завершения операций ввода или вывода. Параллельное программирование позволяет использовать время, которое было бы потрачено на ожидание, для другой задачи.\n",
    "- Более подходящая структура программы - некоторые проблемы и проблемные области хорошо подходят для представления в виде параллельных задач или процессов.\n",
    "\n",
    "### Распространенность (Prevalence)\n",
    "\n",
    "**Конкурентность** широко применяется в вычислениях, начиная с низкоуровневого оборудования на одном кристалле и заканчивая всемирными сетями.\n",
    "\n",
    "На уровне языка программирования:\n",
    "- Канал (Channel)\n",
    "- Сопрограмма (Coroutine)\n",
    "- Futures & promises\n",
    "\n",
    "На уровне операционной системы:\n",
    "- Многозадачность (multitasking) компьютера, включая как совместную многозадачность (cooperative multitasking), так и вытесняющую многозадачность (preemptive multitasking).\n",
    "    - Разделение времени (time-sharing), заменившее последовательную пакетную обработку (batch processing) заданий на конкурентное использование системы.\n",
    "- Процесс (Process)\n",
    "- Поток (Thread)\n",
    "\n",
    "На уровне сети сетевые системы обычно параллельны по своей природе, поскольку состоят из отдельных устройств."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЦПУ (CPU)\n",
    "\n",
    "Центральный процессор (**ЦП**; также центральное процессорное устройствойство - **ЦПУ**; англ. central processing unit, **CPU**, дословно - центральное обрабатывающее устройство, часто просто процессор) — электронный блок либо интегральная **схема, исполняющая машинные инструкции (код программ)**, главная часть аппаратного обеспечения компьютера или программируемого логического контроллера.\n",
    "\n",
    "![intel-core-i7](images/intel-core-i7.jpg)\n",
    "\n",
    "ЦП выполняет основные арифметические (arithmetic), логические (logic), управляющие операции (controlling) и операции ввода-вывода (I/O), указанные в коде программы.\n",
    "\n",
    "Это контрастирует с внешними компонентами, такими как основная память и схемы ввода-вывода, и специализированными процессорами, такими как графические процессоры (GPU).\n",
    "\n",
    "\n",
    "Большинство современных ЦП реализованы на микропроцессорах на интегральных схемах, с одним или несколькими ЦП на одной микросхеме.\n",
    "Микропроцессоры с несколькими процессорами являются **многоядерными (multi-core)** процессорами.\n",
    "\n",
    "\n",
    "Отдельные физические процессоры, ядра процессора, также **могут быть многопоточными (multithreading)** для создания дополнительных **виртуальных или логических процессоров**.\n",
    "\n",
    "\n",
    "Инструкции представляют собой обычные инструкции ЦП (такие как добавление, перемещение данных и переход), но один процессор может одновременно выполнять инструкции на отдельных ядрах, увеличивая общую скорость программ, поддерживающих **многопоточность (multithreading)** или другие методы **параллельных вычислений (parallel computing)**.\n",
    "\n",
    "\n",
    "**Многоядерный (multi-core)** процессор реализует **многопроцессорность (multiprocessing)** в одном физическом корпусе.\n",
    "\n",
    "\n",
    "Повышение производительности при использовании **многоядерного (multi-core)** процессора во многом зависит от используемых программных алгоритмов и их реализации.\n",
    "В частности, возможный выигрыш ограничен той частью программного обеспечения, которое может работать параллельно одновременно на нескольких ядрах (этот эффект описывается **законом Амдала**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чрезвычайная параллельность (Embarrassingly parallel)\n",
    "\n",
    "В лучшем случае, так называемые **чрезвычайно параллельные (embarrassingly parallel)** проблемы могут реализовать показатели ускорения, близкие к количеству ядер, или даже больше, **если проблема разделена настолько, чтобы поместиться в кэш-память каждого ядра, избегая использования гораздо более медленной основной системной памяти**.\n",
    "\n",
    "**Чрезвычайная параллельность (чрезвычайно параллельная задача, англ. embarrassingly parallel)** — тип задач в системах параллельных вычислений, для которых *не требуется прилагать больших усилий при разделении* на несколько отдельных параллельных задач (распараллеливании). Чаще всего не существует зависимости (или связи) между этими параллельными задачами, то есть их результаты не влияют друг на друга.\n",
    "\n",
    "Типичным примером чрезвычайно параллельной задачи является работа графического процессора (GPU) при расчёте 3D проекций, когда каждый пиксель на экране может рассчитываться самостоятельно.\n",
    "\n",
    "Однако большинство приложений не ускоряются так сильно, если программисты не вкладывают чрезмерно много усилий в рефакторинг всей проблемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Закон Амдала (Amdahl's law)\n",
    "\n",
    "**Закон Амдала (англ. Amdahl's law, иногда также Закон Амдаля — Уэра)** — иллюстрирует ограничение роста производительности вычислительной системы с увеличением количества вычислителей. \n",
    "\n",
    "Джин Амдал сформулировал закон в 1967 году, обнаружив простое по существу, но непреодолимое по содержанию ограничение на рост производительности при распараллеливании вычислений: \n",
    "\n",
    "**\"В случае, когда задача разделяется на несколько частей, суммарное время её выполнения на параллельной системе не может быть меньше времени выполнения самого медленного фрагмента\"**. \n",
    "\n",
    "Согласно этому закону, ускорение выполнения программы за счёт распараллеливания её инструкций на множестве вычислителей ограничено временем, необходимым для выполнения её последовательных инструкций.\n",
    "\n",
    "![amdahls_law_ideal_practice](images/amdahls_law.png)\n",
    "\n",
    "**Закон Амдала** показывает, что прирост эффективности вычислений зависит от алгоритма задачи и ограничен сверху для любой задачи.\n",
    "\n",
    "*Не для всякой задачи имеет смысл наращивание числа процессоров в вычислительной системе.*\n",
    "\n",
    "Более того, если учесть время, необходимое для передачи данных между узлами вычислительной системы, то зависимость времени вычислений от числа узлов будет иметь минимум.\n",
    "\n",
    "Это накладывает ограничение на масштабируемость вычислительной системы, то есть означает, что *с определенного момента добавление новых узлов в систему будет увеличивать время расчёта задачи*.\n",
    "\n",
    "![amdahls_law_ideal_practice](images/amdahls_law_ideal_practice.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Закон Густавсона — Барсиса (Gustafson's law)\n",
    "\n",
    "**Закон Густафсона (иногда Густавсона) — Барсиса (англ. Gustafson – Barsis's law)** — оценка максимально достижимого ускорения выполнения параллельной программы, в зависимости от количества одновременно выполняемых потоков вычислений (\"процессоров\") и доли последовательных расчётов.\n",
    "\n",
    "Аналог **закона Амдала**: Джон Густафсон (англ. John L. Gustafson) и Эдвин Барсис (Edwin H. Barsis) представили статью \"Переоценка закона Амдала\" в 1988 году.\n",
    "\n",
    "Данную оценку ускорения называют **ускорением масштабирования (англ. scaled speedup)**, так как данная характеристика показывает, **насколько эффективно могут быть организованы параллельные вычисления при увеличении сложности решаемых задач**.\n",
    "\n",
    "Отличие от **закона Амдала**:\n",
    "При оценке ускорения параллельного выполнения **закон Амдала** предполагает, что объем задачи остается постоянным\n",
    "\n",
    "Величина ускорения по **закону Амдала** показывает, во сколько раз меньше времени потребуется параллельной программе для выполнения. \n",
    "\n",
    "Однако величину ускорения можно рассматривать и как увеличение объема выполненной задачи за постоянный промежуток времени. **Закон Густафсона** появился именно из этого предположения.\n",
    "\n",
    "**Ускорение масштабирования** определяется как отношение объема вычислений, выполненных с использованием многопоточности, к объему вычислений, выполненных последовательно за один и тот же промежуток времени.\n",
    "\n",
    "![gustafson_amdahl_law](images/gustafson_amdahl_law.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Процесс (Process) vs. Поток (Thread)\n",
    "\n",
    "### Процесс\n",
    "\n",
    "**Процесс (process)** — это экземпляр компьютерной программы, которая выполняется одним или несколькими **потоками**. **Процесс** содержит программный код и его действия. В зависимости от операционной системы (ОС) процесс может состоять из нескольких потоков выполнения, которые выполняют инструкции **конкурентно**.\n",
    "\n",
    "**Процесс** является \"самой тяжёлой\" единицей планирования ядра. Собственные ресурсы для процесса выделяются операционной системой.\n",
    "\n",
    "Различные **процессы** могут быть связаны с одной и той же программой. Например, открытие нескольких экземпляров одной и той же программы часто приводит к выполнению более чем одного процесса.\n",
    "\n",
    "Компьютерная программа сама по себе — лишь пассивная последовательность инструкций. В то время как **процесс** — непосредственное выполнение этих инструкций.\n",
    "\n",
    "Операционная система предоставляет механизмы для взаимодействия **процессов** безопасными и предсказуемыми способами.\n",
    "\n",
    "### Поток\n",
    "\n",
    "**Поток выполнения (тред; от англ. thread — нить)** — наименьшая единица обработки, исполнение которой может быть назначено ядром операционной системы.\n",
    "\n",
    "Реализация потоков выполнения и процессов в разных операционных системах отличается друг от друга, но в большинстве случаев **поток выполнения находится внутри процесса**.\n",
    "\n",
    "Несколько **потоков** выполнения могут существовать в рамках одного и того же **процесса** и совместно использовать ресурсы, такие как память, тогда как процессы не разделяют этих ресурсов.\n",
    "\n",
    "В частности, **потоки** выполнения разделяют инструкции **процесса** (его код) и его контекст (значения переменных, которые они имеют в любой момент времени).\n",
    "\n",
    "**Потоки** выполнения ядра относятся к \"лёгким\" единицам планирования ядра.\n",
    "\n",
    "![](images/process_vs_thread_1.png)\n",
    "\n",
    "![](images/process_vs_thread_2.gif)\n",
    "\n",
    "### Отличие потока от процесса\n",
    "\n",
    "**Потоки** выполнения отличаются от традиционных **процессов** многозадачной операционной системы тем, что:\n",
    "- **процессы**, как правило, независимы, тогда как **потоки** выполнения существуют как составные элементы **процессов**\n",
    "- **процессы** несут значительно больше информации о состоянии, тогда как несколько **потоков** выполнения внутри **процесса** совместно используют информацию о состоянии, а также память и другие вычислительные ресурсы\n",
    "- **процессы** имеют отдельные адресные пространства, тогда как **потоки** выполнения совместно используют их адресное пространство\n",
    "- **процессы** взаимодействуют только через предоставляемые системой механизмы связей между процессами\n",
    "- переключение контекста между **потоками** выполнения в одном **процессе**, как правило, быстрее, чем переключение контекста между **процессами**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переключение контекста (Context switch)\n",
    "\n",
    "**Переключение контекста (англ. context switch)** — процесс прекращения выполнения процессором одной задачи (процесса, потока, нити) с сохранением всей необходимой информации и состояния, необходимых для последующего продолжения с прерванного места, и восстановления и загрузки состояния задачи, к выполнению которой переходит процессор.\n",
    "\n",
    "В процедуру **переключения контекста входит** т. н. планирование задачи — процесс принятия решения, какой задаче передать управление.\n",
    "\n",
    "Кроме того, следует учесть следующие факты, влияющие на состояние системы:\n",
    "- *Переключение контекста обычно требует значительных вычислений, и большая часть разработки операционных систем направлена на оптимизацию использования переключений контекста.*\n",
    "- Переключение с одного процесса на другой требует определенного времени для выполнения администрирования - сохранения и загрузки регистров и карт памяти, обновления различных таблиц и списков и т.д.\n",
    "- Само по себе переключение контекста снижает производительность из-за запуска планировщика задач, сброса TLB и косвенно из-за совместного использования кэша ЦП между несколькими задачами.\n",
    "- *Переключение между потоками одного процесса может быть быстрее, чем между двумя отдельными процессами*, поскольку потоки используют одни и те же карты виртуальной памяти.\n",
    "- Содержимое кэша (особенно это касается кэша первого уровня), накопленное и \"оптимизированное\" под выполнение одного потока, оказывается совершенно неприменимым к новому потоку, на который происходит переключение.\n",
    "- При переключении контекста на процесс, который до этого долгое время не использовался, многие страницы могут физически отсутствовать в оперативной памяти, что порождает подгрузку вытесненных страниц из вторичной памяти.\n",
    "\n",
    "В общем случае, при запуске нескольких **потоков** на одном ядре он будет медленнее, так как между потоками есть переключение контекста.\n",
    "![](images/context_switch_vs_sequential.jpg)\n",
    "\n",
    "Когда выполняется что-то с интенсивным использованием ЦП, добавляются накладные расходы, при выполнении параллельных **потоков** на одноядерной машине.\n",
    "\n",
    "В случае, если задачи не требуют интенсивного использования ЦП (ждут ответа на вызов службы или ввода/вывода), то можно очень эффективно запускать параллельные **потоки** на одноядерной машине."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Многопроцессорность (Multiprocessing) vs. Многопоточность (Multithreading)\n",
    "\n",
    "**Многопроцессорность (Мультипроцессорность, Многопроцессорная обработка, англ. Multiprocessing)** — использование пары или большего количества физических процессоров в одной компьютерной системе.\n",
    "\n",
    "\n",
    "Шаги для создания нового потока с помощью модуля `threading`:\n",
    "\n",
    "- Создать класс наследовав его от `threading.Thread`\n",
    "- Переопределить метод `__init__` для предоставления аргументов в соответствии с требованиями.\n",
    "- Переопределить метод `run`, чтобы создать логику потока.\n",
    "\n",
    "Пример многопоточной программы на Python: [m_threading_1.py](./m_threading_1.py) [m_threading_2.py](./m_threading_2.py)\n",
    "\n",
    "Пример многопроцессной программы на Python: [m_processing_1.py](./m_processing_1.py) [m_processing_2.py](./m_processing_2.py)\n",
    "\n",
    "\n",
    "### Профилировка\n",
    "\n",
    "[Intel® VTune™ Profiler](https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/vtune-profiler.html)\n",
    "\n",
    "[Скачать](https://software.intel.com/content/www/us/en/develop/tools/oneapi/base-toolkit/download.html#operatingsystem=Linux&#distributions=Web%20&%20Local%20(recommended)&#options=Local)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread pool\n",
    "\n",
    "![](images/thread_pool.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Глобальная блокировка интерпретатора (Global interpreter lock = GIL)\n",
    "\n",
    "**Глобальная блокировка интерпретатора (англ. Global Interpreter Lock, GIL)** — способ синхронизации потоков, который используется в некоторых интерпретируемых языках программирования, например в **Python (CPython — наиболее распространённая реализация интерпретатора языка Python)** и Ruby.\n",
    "\n",
    "![](images/GIL_description.gif)\n",
    "\n",
    "**GIL** является *самым простым способом* избежать конфликтов при одновременном обращении разных потоков к одним и тем же участкам памяти.\n",
    "\n",
    "Когда один поток захватывает его, **GIL**, работая по принципу *мьютекса*, блокирует остальные.\n",
    "\n",
    "**Нет параллельных потоков — нет конфликтов** при обращении к разделяемым объектам.\n",
    "\n",
    "Очерёдность выполнения потоков определяет интерпретатор в зависимости от реализации, переключение между потоками может происходить: когда активный поток пытается осуществить ввод-вывод, по исчерпании лимита выполненных инструкций, либо по таймеру.\n",
    "\n",
    "Главный **недостаток** подхода обеспечения потокобезопасности при помощи **GIL** — это *ограничение параллельности вычислений*.\n",
    "\n",
    "**GIL** не позволяет достигать наибольшей эффективности вычислений при работе на многоядерных и мультипроцессорных системах.\n",
    "\n",
    "Также использование нескольких потоков накладывает издержки на их переключение из-за эффекта конкуренции (потоки \"пытаются\" перехватить **GIL**). **То есть многопоточное выполнение может занять большее время, чем последовательное выполнение тех же задач.**\n",
    "\n",
    "**Причины использования GIL:**\n",
    "- Однопоточные сценарии выполняются значительно быстрее, чем при использовании других подходов обеспечения потокобезопасности;\n",
    "- Простая интеграция библиотек на C, которые зачастую тоже не потокобезопасны;\n",
    "- Простота реализации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Потоковая безопасность (Thread-safety)\n",
    "\n",
    "**Потоковая безопасность (англ. thread-safety)** — это концепция программирования, применимая к многопоточным программам. Код потокобезопасен, если он функционирует исправно при использовании его из нескольких потоков одновременно. В частности, он должен обеспечивать правильный доступ нескольких потоков к разделяемым данным.\n",
    "\n",
    "В общем случае **потоковая безопасность** достигается *сложно*. Но существует несколько источников выявления нарушений потоковой безопасности:\n",
    "- доступ к глобальным переменным или динамической памяти (куче);\n",
    "- выделение/освобождение ресурсов, имеющих глобальные ограничения (файлы, процессы и др.);\n",
    "- неявный доступ через ссылки и указатели;\n",
    "- побочный эффект функций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadlock\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starvation\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сопрограмма (Coroutine)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Асинхронность\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Coursera_Capstone]",
   "language": "python",
   "name": "conda-env-Coursera_Capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
