{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/c/home-data-for-ml-course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ira/anaconda3/envs/LevelUp_DataScience\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  conda-forge\n",
      "    libstdcxx-ng-9.3.0         |      h2ae2ef3_17         4.0 MB  conda-forge\n",
      "    libxgboost-1.3.0           |       h9c3ff4c_1         3.3 MB  conda-forge\n",
      "    py-xgboost-1.3.0           |   py38h578d9bd_1         124 KB  conda-forge\n",
      "    xgboost-1.3.0              |   py38h709712a_1          11 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         7.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  conda-forge/linux-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  libxgboost         conda-forge/linux-64::libxgboost-1.3.0-h9c3ff4c_1\n",
      "  py-xgboost         conda-forge/linux-64::py-xgboost-1.3.0-py38h578d9bd_1\n",
      "  xgboost            conda-forge/linux-64::xgboost-1.3.0-py38h709712a_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  libstdcxx-ng       pkgs/main::libstdcxx-ng-9.1.0-hdf63c6~ --> conda-forge::libstdcxx-ng-9.3.0-h2ae2ef3_17\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libstdcxx-ng-9.3.0   | 4.0 MB    | ##################################### | 100% \n",
      "py-xgboost-1.3.0     | 124 KB    | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "libxgboost-1.3.0     | 3.3 MB    | ##################################### | 100% \n",
      "xgboost-1.3.0        | 11 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "!conda install -c conda-forge xgboost -y\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home_data = pd.read_csv(\"./data/hpc_train.csv\")\n",
    "home_data = pd.read_csv(\"./hpc_train_data.csv\")\n",
    "home_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = home_data.SalePrice\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission_linear(model_name, model, features):\n",
    "    # read test data file using pandas\n",
    "    test_data = pd.read_csv(\"./data/hpc_test.csv\")\n",
    "\n",
    "    # create test_X which comes from test_data but includes only the columns you used for prediction.\n",
    "    # The list of columns is stored in a variable called features\n",
    "\n",
    "    test_X = test_data[features]\n",
    "\n",
    "    # make predictions which we will submit. \n",
    "    test_preds = model.predict(test_X)\n",
    "\n",
    "    # The lines below shows you how to save your data in the format needed to score it in the competition\n",
    "    output = pd.DataFrame({'Id': test_data.Id,\n",
    "                           'SalePrice': test_preds})\n",
    "    \n",
    "    output_file = f'submission_{model_name}.csv'\n",
    "    output.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f'{output_file} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_data_num = home_data.select_dtypes(include=[np.number])\n",
    "home_data_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_modelession_and_save_submission_linear(model_type, features):\n",
    "    X = home_data_num[features]\n",
    "    print('X:', X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=100)\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Coefficients:', model.coef_)\n",
    "    print('Intercept:', model.intercept_)\n",
    "\n",
    "    y_predicted = model.predict(X_test)\n",
    "\n",
    "    print(f'R2: {r2_score(y_true=y_test, y_pred=y_predicted)}')\n",
    "    print(f\"MSE: {mean_absolute_error(y_true=y_test, y_pred=y_predicted)}\")\n",
    "    \n",
    "    save_submission_linear(f'{model_type}_modelession', model, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['OverallQual']\n",
    "\n",
    "use_modelession_and_save_submission_linear(model_type='simple', features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['OverallQual', \n",
    "            'GrLivArea', \n",
    "            '1stFlrSF',\n",
    "            'YearBuilt',\n",
    "            'FullBath',\n",
    "            'Fireplaces'\n",
    "#             'GarageCars', \n",
    "#             'TotalBsmtSF',\n",
    "#             'GarageArea'\n",
    "           ]\n",
    "\n",
    "use_modelession_and_save_submission_linear(model_type='multiple', features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission_linear(model_name, model, features, poly):\n",
    "    # read test data file using pandas\n",
    "    test_data = pd.read_csv(\"./data/hpc_test.csv\")\n",
    "\n",
    "    # create test_X which comes from test_data but includes only the columns you used for prediction.\n",
    "    # The list of columns is stored in a variable called features\n",
    "\n",
    "    test_X = test_data[features]\n",
    "    \n",
    "    X_test_poly = poly.fit_transform(test_X)\n",
    "\n",
    "    # make predictions which we will submit. \n",
    "    test_preds = model.predict(X_test_poly)\n",
    "\n",
    "    # The lines below shows you how to save your data in the format needed to score it in the competition\n",
    "    output = pd.DataFrame({'Id': test_data.Id,\n",
    "                           'SalePrice': test_preds})\n",
    "    \n",
    "    output_file = f'submission_{model_name}.csv'\n",
    "    output.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f'{output_file} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_polynomial_regression_and_save_submission_linear(features):\n",
    "    X = home_data_num[features]\n",
    "    print('X:', X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=100)\n",
    "    \n",
    "    \n",
    "    for degree in range(2, 10):\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_train_poly = poly.fit_transform(X_train)\n",
    "\n",
    "        model = linear_model.LinearRegression()\n",
    "        model.fit(X_train_poly, y_train)\n",
    "#         print('Coefficients:', model.coef_)\n",
    "#         print('Intercept:', model.intercept_)\n",
    "        \n",
    "        X_test_poly = poly.fit_transform(X_test)\n",
    "        y_predicted = model.predict(X_test_poly)\n",
    "\n",
    "        print(f'R2: {r2_score(y_true=y_test, y_pred=y_predicted)}')\n",
    "        print(f\"MSE: {mean_absolute_error(y_true=y_test, y_pred=y_predicted)}\")\n",
    "\n",
    "        save_submission_linear(f'polynomial-{degree}_regression', \n",
    "                               model, \n",
    "                               features, \n",
    "                               poly)\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "features = ['OverallQual', \n",
    "            'GrLivArea', \n",
    "            '1stFlrSF',\n",
    "            'YearBuilt',\n",
    "            'FullBath',\n",
    "            'Fireplaces'\n",
    "           ]\n",
    "\n",
    "use_polynomial_regression_and_save_submission_linear(features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['LotArea', \n",
    "#             'YearBuilt', \n",
    "#             '1stFlrSF', \n",
    "#             '2ndFlrSF', \n",
    "#             'FullBath', \n",
    "#             'BedroomAbvGr', \n",
    "#             'TotRmsAbvGrd']\n",
    "\n",
    "features = ['OverallQual', \n",
    "            'GrLivArea', \n",
    "            '1stFlrSF',\n",
    "            'YearBuilt',\n",
    "            'FullBath',\n",
    "            'Fireplaces'\n",
    "           ]\n",
    "\n",
    "X = home_data[features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost hyper-parameter tuning\n",
    "def hyperParameterTuning(X_train, y_train):\n",
    "    param_tuning = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [x for x in range(2, 11, 1)],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'subsample': [0.5, 0.7],\n",
    "        'colsample_bytree': [0.5, 0.7],\n",
    "        'n_estimators' : [x for x in range(100, 1000, 100)],\n",
    "        'objective': ['reg:squarederror']\n",
    "    }\n",
    "    \n",
    "    xgb_model = XGBRegressor()\n",
    "\n",
    "    gsearch = GridSearchCV(estimator = xgb_model,\n",
    "                           param_grid = param_tuning,                        \n",
    "                           scoring = 'neg_mean_absolute_error', #MAE\n",
    "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
    "                           cv = 5,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1)\n",
    "\n",
    "    gsearch.fit(X_train, y_train)\n",
    "\n",
    "    return gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only in the first run of the kernel\n",
    "hyperParameterTuning(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best params:**\n",
    "\n",
    "<!-- {'colsample_bytree': 0.7,\n",
    " 'learning_rate': 0.1,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 3,\n",
    " 'n_estimators': 100,\n",
    " 'objective': 'reg:squarederror',\n",
    " 'subsample': 0.5} -->\n",
    " \n",
    " {'colsample_bytree': 0.5,\n",
    " 'learning_rate': 0.1,\n",
    " 'max_depth': 3,\n",
    " 'min_child_weight': 1,\n",
    " 'n_estimators': 100,\n",
    " 'objective': 'reg:squarederror',\n",
    " 'subsample': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(\n",
    "        colsample_bytree = 0.7,\n",
    "        learning_rate = 0.01,\n",
    "        max_depth = 5,\n",
    "        min_child_weight = 1,\n",
    "        n_estimators = 500,\n",
    "        objective = 'reg:squarederror',\n",
    "        subsample = 0.7)\n",
    "\n",
    "%time model.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission_xgboost(model_name, model, features):\n",
    "    # read test data file using pandas\n",
    "    test_data = pd.read_csv(\"./data/hpc_test.csv\")\n",
    "\n",
    "    # create test_X which comes from test_data but includes only the columns you used for prediction.\n",
    "    # The list of columns is stored in a variable called features\n",
    "\n",
    "    test_X = test_data[features]\n",
    "    \n",
    "    # make predictions which we will submit. \n",
    "    test_preds = model.predict(test_X)\n",
    "\n",
    "    # The lines below shows you how to save your data in the format needed to score it in the competition\n",
    "    output = pd.DataFrame({'Id': test_data.Id,\n",
    "                           'SalePrice': test_preds})\n",
    "    \n",
    "    output_file = f'submission_{model_name}.csv'\n",
    "    output.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f'{output_file} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission_xgboost('xgboost', model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LevelUp_DataScience] *",
   "language": "python",
   "name": "conda-env-LevelUp_DataScience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
