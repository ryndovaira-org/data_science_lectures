{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density-based spatial clustering of applications with noise (DBSCAN) / Основанная на плотности пространственная кластеризация для приложений с шумами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Источники:**\n",
    "\n",
    "\n",
    "[Density-based spatial clustering of applications with noise (DBSCAN)](https://en.wikipedia.org/wiki/DBSCAN)\n",
    "\n",
    "[Основанная на плотности пространственная кластеризация для приложений с шумами](https://ru.wikipedia.org/wiki/DBSCAN)\n",
    "\n",
    "[DBSCAN](https://scikit-learn.org/stable/modules/clustering.html#dbscan)\n",
    "\n",
    "[Интересные алгоритмы кластеризации, часть вторая: DBSCAN](https://habr.com/ru/post/322034/)\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ВНИМАНИЕ: необходимо удостовериться, что виртуальная среда выбрана правильно!\n",
    "\n",
    "# Для MacOS/Ubuntu\n",
    "# !which pip\n",
    "\n",
    "# Для Windows\n",
    "# !where pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !conda install matplotlib numpy scikit-learn seaborn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !conda install basemap matplotlib -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge umap-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import umap\n",
    "from umap import UMAP\n",
    "\n",
    "umap.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание\n",
    "\n",
    "DBSCAN — это алгоритм кластеризации данных, который предложили Маритин Эстер, Ганс-Петер Кригель, Ёрг Сандер и Сяовэй Су в 1996.\n",
    "\n",
    "**Подходит для данных, содержащих кластеры одинаковой плотности.**\n",
    "\n",
    "Это алгоритм кластеризации, **основанной на плотности** — если дан набор точек в некотором пространстве, алгоритм **группирует точки, которые тесно расположены** (точки со многими близкими соседями), **помечая как выбросы** точки, которые находятся одиноко в областях с малой плотностью (ближайшие соседи которых лежат далеко).\n",
    "\n",
    "**DBSCAN является одним из наиболее часто используемых алгоритмов кластеризации, и наиболее часто упоминается в научной литературе.**\n",
    "\n",
    "В 2014 алгоритм получил премию \"проверено временем (test of time)\" (премия даётся алгоритмам, которые получили существенное внимание в теории и практике) на ведущей конференции по интеллектуальному анализу данных.\n",
    "\n",
    "\n",
    "Самые важные гиперпараметры [sklearn.cluster.DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html):\n",
    "\n",
    "- **`eps (default=0.5)`** - максимальное расстояние между двумя примерами (samples), чтобы один считался соседним с другим. Это не максимальная граница расстояний до точек в кластере. Это наиболее важный параметр DBSCAN, который нужно выбрать в соответствии с набором данных и функцией расстояния (`metric`).\n",
    "\n",
    "- **`min_samples (default=5)`** - количество примеров (samples) или общий вес в окрестности точки, которая будет считаться базовой точкой. Сюда входит и сама точка.\n",
    "\n",
    "Любая задача интеллектуальной обработки данных имеет проблему параметров. \n",
    "\n",
    "Любой параметр специфично влияет на алгоритм. Для алгоритма DBSCAN нужны параметры `eps`  и `min_samples`.\n",
    "\n",
    "**В идеале, значение `eps`  определяется решаемой задачей (например, физические расстояния), а `min_samples` определяет тогда минимальный желаемый размер кластера.**\n",
    "\n",
    "**OPTICS** можно рассматривать как **обобщение DBSCAN**, в котором параметр **`eps`  заменяется максимальным значением**, наиболее воздействущим на эффективность. **`min_samples` тогда становится минимальным размером кластера**. \n",
    "\n",
    "Хотя алгоритм **OPTICS** существенно проще в области выбора параметров, чем DBSCAN, его результаты труднее использовать, так как он обычно даёт иерархическую кластеризацию вместо простого разделения, которое даёт DBSCAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекомендации по выбору гиперпараметров `eps`  и `min_samples`\n",
    "\n",
    "- **`min_samples`**\n",
    "\n",
    "    - Минимальное значение `min_samples` может быть получено из размерности `D` (например, 2D, 3D, 8D = количество признаков) набора данных как $min\\_samples \\geqslant D +1$. \n",
    "    \n",
    "    - Низкое значение $min\\_samples=1$ не имеет смысла, так как тогда любая точка будет кластером.\n",
    "    \n",
    "    - Для $min\\_samples \\leqslant 2$ результат будет тем же самым, что и иерархическая кластеризация с метрикой единичного соединения с отсечением дендрограммы на высоте `eps`.\n",
    "    \n",
    "    - **`min_samples` должен быть равным как минимум 3**. \n",
    "    \n",
    "    - Для наборов данных **с шумами бо́льшие значения `min_samples` обычно лучше**, и дают более существенные кластеры. \n",
    "    \n",
    "    - Эмпирика показывает, что может быть использовано значение $min\\_samples = 2 * D$, но может оказаться необходимым **выбор большего значения для больших наборов данных**, для данных с шумом или для данных, содержащих много дубликатов.\n",
    " \n",
    "\n",
    "- **`eps`**\n",
    "\n",
    "    - Значение `eps` может быть выбрано с помощью графа k-расстояний, вычерчивая расстояние `k` ($k = min\\_samples - 1$) ближайшему соседу в порядке от большего к меньшему.\n",
    "    \n",
    "    - **Хорошие значения `eps` те, где график имеет \"изгиб\"**.\n",
    "    \n",
    "    - **Если `eps` выбрана слишком малыми, большая часть данных не будет кластеризована, а для слишком больших значений `eps`  кластеры будут сливаться и большинство объектов окажутся в одном кластере**.\n",
    "    \n",
    "    - Обычно **малые значения `eps`  предпочтительнее** и опыт показывает, что только небольшая доля точек должна быть с этим расстоянием друг от друга.\n",
    "    \n",
    "    - Альтернативно, может быть использован график OPTICS для выбора `eps`, но тогда и сам алгоритм OPTICS может быть использован для кластеризации.\n",
    "    \n",
    "- **`metric`**: \n",
    "\n",
    "    - Выбор функции расстояния сильно связан с выбором `eps` и имеет большое влияние на результаты.\n",
    "    \n",
    "    - Обычно сначала необходимо определить обоснованные меры похожести набора данных, прежде чем выбирать параметр `eps`.\n",
    "    \n",
    "    - Нет оценок для этого параметра, но **функции расстояния следует выбирать согласно набору данных**.\n",
    "    \n",
    "    - Например, для географических данных, расстояние по дуге большого круга часто будет хорошим выбором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преимущества\n",
    "\n",
    "- DBSCAN **не требует указать число кластеров** в данных априори в отличие от метода k-средних.\n",
    "\n",
    "- DBSCAN может найти **кластеры произвольной формы**. \n",
    "    - DBSCAN может найти даже кластеры полностью окружённые (но не связанные с) другими кластерами.\n",
    "    - Благодаря параметру `min_samples` уменьшается так называемый эффект одной связи (связь различных кластеров тонкой линией точек).\n",
    "\n",
    "\n",
    "- DBSCAN имеет понятие шума и **устойчив к выбросам**.\n",
    "\n",
    "- DBSCAN требует лишь двух параметров и большей частью **нечувствителен к порядку точек** в наборе данных.\n",
    "    - Однако, точки, находящиеся на границе двух различных кластеров могут оказаться в другом кластере, если изменить порядок точек, а назначение кластеров единственно с точностью до [изоморфизма](https://ru.wikipedia.org/wiki/%D0%98%D0%B7%D0%BE%D0%BC%D0%BE%D1%80%D1%84%D0%B8%D0%B7%D0%BC).\n",
    "\n",
    "\n",
    "- DBSCAN разработан для применения с базами данных, которые позволяют ускорить запросы в диапазоне значений, например, с помощью [R*-дерева](https://ru.wikipedia.org/wiki/R*-%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE).\n",
    "\n",
    "- Параметры `min_samples` и `eps`  могут быть установлены экспертами в рассматриваемой области, если данные хорошо понимаются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Недостатки\n",
    "\n",
    "- DBSCAN **не полностью однозначен — краевые точки, которые могут быть достигнуты из более чем одного кластера, могут принадлежать любому из этих кластеров, что зависит от порядка просмотра точек**.\n",
    "    - Для большинства наборов данных эти ситуации возникают редко и имеют малое влияние на результат кластеризации — основные точки и шум DBSCAN обрабатывает однозначно. \n",
    "    - Существует версия DBSCAN, которая трактует краевые точки как шум и тем самым достигается полностью однозначный результат, а также более согласованная статистическая интерпретация связных по плотности компонент.\n",
    "\n",
    "- Качество DBSCAN **зависит от измерения расстояния (`metric`)**.\n",
    "    - Наиболее часто используемой метрикой расстояний является евклидова метрика. \n",
    "    - Особенно для кластеризации **данных высокой размерности евклидова метрика может оказаться почти бесполезной** ввиду так называемого \"[проклятия размерности](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D0%BA%D0%BB%D1%8F%D1%82%D0%B8%D0%B5_%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8)\", что делает трудным делом нахождение подходящего значения `eps`. \n",
    "    - Этот эффект, однако, присутствует в любом другом алгоритме, основанном на евклидовом расстоянии.\n",
    "\n",
    "- DBSCAN не может хорошо кластеризовать наборы данных **с большой разницей в плотности**, поскольку не удается выбрать приемлемую для всех кластеров комбинацию `min_samples` и `eps`.\n",
    "\n",
    "- Если данные и масштаб не вполне хорошо поняты, **выбор осмысленного порога расстояния `eps`  может оказаться трудным**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "\n",
    "[Источник (custDatasets)](https://www.kaggle.com/gangliu/custdatasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../../data/Cust_Segmentation.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ данных\n",
    "\n",
    "См. лекцию [02_pca](../../08_modeling_ml_demensionality_reduction/lectures/02_pca.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['Defaulted'].fillna(0, inplace=True)\n",
    "df['Defaulted'] = df['Defaulted'].astype(int)\n",
    "df['Defaulted'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "norm_trans = QuantileTransformer(output_distribution='normal', n_quantiles=100)\n",
    "df_norm = pd.DataFrame(norm_trans.fit_transform(df[num_cols]), columns=num_cols)\n",
    "df_norm.hist(bins=30, figsize=(15, 5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-D PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pca_3 = PCA(n_components=3)\n",
    "df_pca_3 = pd.DataFrame(pca_3.fit_transform(df_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = Axes3D(fig, azim=-135, elev=35)\n",
    "\n",
    "ax.scatter(df_pca_3[0], df_pca_3[1], df_pca_3[2],\n",
    "           alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-D UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umap_3 = UMAP(n_components=3)\n",
    "df_umap_3 = pd.DataFrame(umap_3.fit_transform(df_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = Axes3D(fig, azim=25, elev=35)\n",
    "\n",
    "ax.scatter(df_umap_3[0], df_umap_3[1], df_umap_3[2], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор `min_samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = len(df_norm.columns) + 1\n",
    "min_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор `eps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# рассчитать среднее расстояние между каждой точкой \n",
    "# в наборе данных и ее min_samples ближайшими соседями \n",
    "neighbors = NearestNeighbors(n_neighbors=min_samples-1)\n",
    "neighbors_fit = neighbors.fit(df_norm)\n",
    "distances, indices = neighbors_fit.kneighbors(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сортировка значений расстояний по возрастанию и построение графика\n",
    "distances = np.sort(distances, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = distances[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оптимальное значение для epsilon будет найдено \n",
    "# в точке максимальной кривизны\n",
    "plt.plot(distances)\n",
    "plt.xlabel('distances')\n",
    "plt.ylabel('epsilon')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=epsilon, min_samples=min_samples).fit(df_norm)\n",
    "labels = db.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = np.unique(labels)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-D PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = Axes3D(fig, azim=-125, elev=35)\n",
    "\n",
    "ax.scatter(df_pca_3[0], df_pca_3[1], df_pca_3[2], \n",
    "           c=labels, \n",
    "           alpha=0.3, \n",
    "           cmap='hsv', \n",
    "           s=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-D UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D    \n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = Axes3D(fig, azim=142, elev=35)\n",
    "\n",
    "ax.scatter(df_umap_3[0], df_umap_3[1], df_umap_3[2], \n",
    "           c=labels, \n",
    "           alpha=0.3, \n",
    "           cmap='hsv', \n",
    "           s=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ \"представителей\" кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Cluster\"] = labels\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('Cluster').mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = {}\n",
    "cluster_examples = pd.DataFrame()\n",
    "\n",
    "for c in clusters:\n",
    "    print(f'Cluster = {c}')\n",
    "    df_clusters[c] = df[df.Cluster == c]\n",
    "    cluster_examples = cluster_examples.append(df[df.Cluster == c].head(1))\n",
    "    display(cluster_examples)\n",
    "    display(df_clusters[c])\n",
    "    display(df_clusters[c].describe())\n",
    "    print('\\n', '=' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "sns.scatterplot(x=df.Edu, \n",
    "                y=df.Defaulted, \n",
    "                size=df.Income, \n",
    "                sizes=(10, 450), \n",
    "                hue=df.Cluster, \n",
    "                palette='hsv', \n",
    "                alpha=0.3,\n",
    "                ax=ax)\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 10))\n",
    "\n",
    "sns.scatterplot(x=df.Edu, \n",
    "                y=df['Years Employed'], #df.Defaulted, \n",
    "                size=df.Defaulted, \n",
    "                sizes=(250, 50), \n",
    "                hue=df.Cluster, \n",
    "                palette='hsv', \n",
    "                alpha=0.3,\n",
    "                ax=ax)\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = Axes3D(fig, azim=-45, elev=25)\n",
    "\n",
    "\n",
    "ax.scatter(df.Edu, df.Defaulted, df['Years Employed'], #df.Income, \n",
    "           c=df.Cluster,\n",
    "           alpha=0.3, \n",
    "           s=60, \n",
    "           cmap='hsv')\n",
    "\n",
    "ax.set_xlabel('Education')\n",
    "ax.set_ylabel('Defaulted')\n",
    "ax.set_zlabel('Years Employed')\n",
    "# ax.set_zlabel('Income')\n",
    "\n",
    "\n",
    "ax.scatter(cluster_examples.Edu, cluster_examples.Defaulted, cluster_examples['Years Employed'], marker='*',\n",
    "           c=\"white\", alpha=1, s=500, edgecolor='k')\n",
    "\n",
    "for row, c in enumerate(cluster_examples.Cluster):\n",
    "    ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                s=400, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LevelUp_DataScience] *",
   "language": "python",
   "name": "conda-env-LevelUp_DataScience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
