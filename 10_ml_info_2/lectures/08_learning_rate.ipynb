{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Коэффициент скорости обучения (Learning rate/eta/alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Источники:**\n",
    "\n",
    "[Коэффициент скорости обучения (Learning rate)](https://wiki.loginom.ru/articles/learning-rate.html)\n",
    "\n",
    "[Learning rate](https://en.wikipedia.org/wiki/Learning_rate)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание\n",
    "\n",
    "В машинном обучении и статистике **коэффициент скорости обучения - это параметр настройки в алгоритме оптимизации, который определяет размер шага на каждой итерации при приближении к минимуму функции потерь.**\n",
    "\n",
    "**Коэффициент скорости обучения – это гиперпараметр, определяющий порядок того, как будут корректироваться веса с учётом функции потерь в градиентном спуске.**\n",
    "\n",
    "Чем **ниже величина, тем медленнее движение** по наклонной.\n",
    "\n",
    "Хотя направление спуска обычно определяется по градиенту функции потерь, **скорость обучения определяет, насколько большой шаг** будет сделан в этом направлении.\n",
    "\n",
    "<img src=\"images/cost_function.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор коэффициента скорости обучения\n",
    "\n",
    "**Выбор параметра противоречив.**\n",
    "\n",
    "<img src=\"images/learning_rate.png\" width=800>\n",
    "\n",
    "- Обычно выбирается в диапазоне **от `0` до `1`**. \n",
    "\n",
    "\n",
    "- **`0` указывать бессмысленно**, поскольку в этом случае корректировка весов вообще производиться не будет.\n",
    "\n",
    "\n",
    "- При установке скорости обучения существует **компромисс между скоростью сходимости и промахом (convergence and overshooting)**.\n",
    "\n",
    "\n",
    "- Большие значения (**`0.7` — `1.0`**) будут соответствовать большому значению шага коррекции. \n",
    "    - **Слишком высокая скорость** обучения заставит обучение **перескочить через минимум**.\n",
    "    - При этом алгоритм будет работать **быстрее** (т.е. для поиска минимума функции ошибки потребуется меньше итераций). Однако **может снизиться точность** настройки модели на минимум функции ошибки, что потенциально увеличит ошибку обучения.\n",
    "\n",
    "\n",
    "- Малые значения коэффициента (**`0.1` — `0.3`**) соответствуют меньшему шагу коррекции весов.\n",
    "    - Слишком **низкая скорость** обучения либо **займет слишком много времени**, чтобы сойтись, либо **застрянет в нежелательном локальном минимуме**.\n",
    "    - В этом случае число шагов (или эпох) обучения, требуемое для поиска экстремума, как правило, увеличивается, но **возрастает точность настройки алгоритма** на минимум функции ошибки, что потенциально уменьшает ошибку обучения. \n",
    "\n",
    "\n",
    "- На практике коэффициент скорости обучения **обычно подбирают экспериментально**.\n",
    "\n",
    "\n",
    "- Чтобы достичь более быстрой сходимости, предотвратить колебания (oscillations) и застревание в нежелательных локальных минимумах, скорость обучения **часто изменяется во время обучения** либо в соответствии с графиком скорости обучения, либо с использованием **адаптивной скорости обучения (Adagrad, Adadelta, RMSprop, Adam)**.\n",
    "\n",
    "<img src=\"images/overfitting_learning_rate.png\" width=800>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LevelUp_DataScience] *",
   "language": "python",
   "name": "conda-env-LevelUp_DataScience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
